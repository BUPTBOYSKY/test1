{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e86681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a416cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./train.csv\",parse_dates=[\"Date\"],index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab54faea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d69a828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5203, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe6f18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-25</th>\n",
       "      <td>356.730774</td>\n",
       "      <td>362.980774</td>\n",
       "      <td>352.403839</td>\n",
       "      <td>353.365387</td>\n",
       "      <td>197.122452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-26</th>\n",
       "      <td>357.211548</td>\n",
       "      <td>360.096161</td>\n",
       "      <td>342.788452</td>\n",
       "      <td>343.269226</td>\n",
       "      <td>191.490234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-29</th>\n",
       "      <td>345.153839</td>\n",
       "      <td>355.769226</td>\n",
       "      <td>338.461548</td>\n",
       "      <td>341.384613</td>\n",
       "      <td>190.439011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-30</th>\n",
       "      <td>344.307678</td>\n",
       "      <td>355.923065</td>\n",
       "      <td>341.692322</td>\n",
       "      <td>355.769226</td>\n",
       "      <td>198.463318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-31</th>\n",
       "      <td>359.615387</td>\n",
       "      <td>361.153839</td>\n",
       "      <td>350.461548</td>\n",
       "      <td>353.692322</td>\n",
       "      <td>197.304749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close\n",
       "Date                                                                  \n",
       "2001-01-25  356.730774  362.980774  352.403839  353.365387  197.122452\n",
       "2001-01-26  357.211548  360.096161  342.788452  343.269226  191.490234\n",
       "2001-01-29  345.153839  355.769226  338.461548  341.384613  190.439011\n",
       "2001-01-30  344.307678  355.923065  341.692322  355.769226  198.463318\n",
       "2001-01-31  359.615387  361.153839  350.461548  353.692322  197.304749"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750dae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>99.529999</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>99.519997</td>\n",
       "      <td>102.959999</td>\n",
       "      <td>102.789993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-24</th>\n",
       "      <td>102.660004</td>\n",
       "      <td>104.199997</td>\n",
       "      <td>102.599998</td>\n",
       "      <td>103.800003</td>\n",
       "      <td>103.709198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-27</th>\n",
       "      <td>104.550003</td>\n",
       "      <td>106.330002</td>\n",
       "      <td>104.389999</td>\n",
       "      <td>105.349998</td>\n",
       "      <td>105.257835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-28</th>\n",
       "      <td>105.290001</td>\n",
       "      <td>106.750000</td>\n",
       "      <td>104.730003</td>\n",
       "      <td>105.730003</td>\n",
       "      <td>105.637512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>105.309998</td>\n",
       "      <td>106.279999</td>\n",
       "      <td>106.187027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close\n",
       "Date                                                                  \n",
       "2021-09-23   99.529999  104.080002   99.519997  102.959999  102.789993\n",
       "2021-09-24  102.660004  104.199997  102.599998  103.800003  103.709198\n",
       "2021-09-27  104.550003  106.330002  104.389999  105.349998  105.257835\n",
       "2021-09-28  105.290001  106.750000  104.730003  105.730003  105.637512\n",
       "2021-09-29  106.000000  107.000000  105.309998  106.279999  106.187027"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f685196",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split=round(len(df)*0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c435d2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6815e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training=df[:-1041]\n",
    "df_for_testing=df[-1041:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "164f3e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4162, 5)\n",
      "(1041, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_for_training.shape)\n",
    "print(df_for_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a86012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_for_training_scaled = scaler.fit_transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5697bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_testing_scaled=scaler.transform(df_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33a6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85398707, 0.86281807, 0.85292546, 0.8403402 , 0.82180889],\n",
       "       [0.85533406, 0.85473269, 0.82623316, 0.8122593 , 0.79289309],\n",
       "       [0.82155169, 0.84260459, 0.81422168, 0.80701755, 0.78749611],\n",
       "       ...,\n",
       "       [0.40689652, 0.40362224, 0.41960282, 0.40436458, 0.7632948 ],\n",
       "       [0.40517242, 0.39995691, 0.41832161, 0.4075738 , 0.76889077],\n",
       "       [0.40862067, 0.39974127, 0.41426436, 0.39880189, 0.75359571]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b668b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4162, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88390259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_testing_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6a58026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里注意，是多变量预测单变量，所以这里有一些修改\n",
    "def createXY(dataset,n_past):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(n_past, len(dataset)):\n",
    "            dataX.append(dataset[i - n_past:i, 1:dataset.shape[1]])#分X和Y的时候，X就是当前的数据，Y也是当前的数据，然后只用当前的X来预测Y有点像BP神经网络，但是这个考虑到了时间的因素\n",
    "            dataY.append(dataset[i-n_past:i,0])\n",
    "    return np.array(dataX),np.array(dataY)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18b62d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=createXY(df_for_training_scaled,1)#用当前X来预测Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2795bf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.86281807 0.85292546 0.8403402  0.82180889]]\n",
      "\n",
      " [[0.85473269 0.82623316 0.8122593  0.79289309]]\n",
      "\n",
      " [[0.84260459 0.81422168 0.80701755 0.78749611]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.40146615 0.42024345 0.4058622  0.76590638]]\n",
      "\n",
      " [[0.40362224 0.41960282 0.40436458 0.7632948 ]]\n",
      "\n",
      " [[0.39995691 0.41832161 0.4075738  0.76889077]]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0587394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85398707]\n",
      " [0.85533406]\n",
      " [0.82155169]\n",
      " ...\n",
      " [0.40926723]\n",
      " [0.40689652]\n",
      " [0.40517242]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cf9decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX,testY=createXY(df_for_testing_scaled,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdaf6a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX Shape--  (4161, 1, 4)\n",
      "trainY Shape--  (4161, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"trainX Shape-- \",trainX.shape)\n",
    "print(\"trainY Shape-- \",trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c78e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testX Shape--  (1040, 1, 4)\n",
      "testY Shape--  (1040, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"testX Shape-- \",testX.shape)\n",
    "print(\"testY Shape-- \",testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbf9d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX[0]-- \n",
      " [[0.86281807 0.85292546 0.8403402  0.82180889]]\n",
      "\n",
      "trainY[0]--  [0.85398707]\n"
     ]
    }
   ],
   "source": [
    "print(\"trainX[0]-- \\n\",trainX[0])\n",
    "print(\"\\ntrainY[0]-- \",trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d165e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42ffe2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86157\\AppData\\Local\\Temp\\ipykernel_30644\\2145507911.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n"
     ]
    }
   ],
   "source": [
    "def build_model(optimizer):\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(trainX.shape[1],trainX.shape[2])))\n",
    "    grid_model.add(LSTM(50))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(1))\n",
    "\n",
    "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    return grid_model\n",
    "\n",
    "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
    "parameters = {'batch_size' : [1,20],\n",
    "              'epochs' : [81,82],\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fc54625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/81\n",
      "2080/2080 [==============================] - 5s 2ms/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 2/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 5.5253e-04 - val_loss: 6.2083e-04\n",
      "Epoch 3/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 3.4065e-04 - val_loss: 0.0011\n",
      "Epoch 4/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 2.2107e-04 - val_loss: 3.5668e-04\n",
      "Epoch 5/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.8147e-04 - val_loss: 2.8505e-04\n",
      "Epoch 6/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.4957e-04 - val_loss: 4.3336e-04\n",
      "Epoch 7/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.4915e-04 - val_loss: 2.2518e-04\n",
      "Epoch 8/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3439e-04 - val_loss: 3.8325e-04\n",
      "Epoch 9/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3638e-04 - val_loss: 1.0761e-04\n",
      "Epoch 10/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2528e-04 - val_loss: 3.8854e-05\n",
      "Epoch 11/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2646e-04 - val_loss: 5.5215e-04\n",
      "Epoch 12/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3159e-04 - val_loss: 4.1944e-04\n",
      "Epoch 13/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3144e-04 - val_loss: 1.0318e-04\n",
      "Epoch 14/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2528e-04 - val_loss: 8.7627e-04\n",
      "Epoch 15/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2661e-04 - val_loss: 1.4653e-04\n",
      "Epoch 16/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2493e-04 - val_loss: 1.3117e-04\n",
      "Epoch 17/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1888e-04 - val_loss: 1.4933e-04\n",
      "Epoch 18/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2464e-04 - val_loss: 1.4827e-05\n",
      "Epoch 19/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2711e-04 - val_loss: 0.0012\n",
      "Epoch 20/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2206e-04 - val_loss: 2.0063e-05\n",
      "Epoch 21/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3184e-04 - val_loss: 1.9257e-04\n",
      "Epoch 22/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2057e-04 - val_loss: 3.3186e-05\n",
      "Epoch 23/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1850e-04 - val_loss: 3.8923e-05\n",
      "Epoch 24/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1633e-04 - val_loss: 9.4809e-05\n",
      "Epoch 25/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1797e-04 - val_loss: 5.1137e-04\n",
      "Epoch 26/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1048e-04 - val_loss: 8.5793e-05\n",
      "Epoch 27/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1741e-04 - val_loss: 1.3133e-04\n",
      "Epoch 28/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2197e-04 - val_loss: 1.0589e-04\n",
      "Epoch 29/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2202e-04 - val_loss: 7.2709e-05\n",
      "Epoch 30/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1767e-04 - val_loss: 6.9537e-05\n",
      "Epoch 31/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2161e-04 - val_loss: 5.4095e-05\n",
      "Epoch 32/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 1.1144e-04 - val_loss: 4.8785e-04\n",
      "Epoch 33/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1527e-04 - val_loss: 3.4819e-04\n",
      "Epoch 34/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2235e-04 - val_loss: 2.3938e-05\n",
      "Epoch 35/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2094e-04 - val_loss: 4.9070e-04\n",
      "Epoch 36/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1655e-04 - val_loss: 4.2969e-04\n",
      "Epoch 37/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0537e-04 - val_loss: 4.7763e-05\n",
      "Epoch 38/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1887e-04 - val_loss: 2.1876e-05\n",
      "Epoch 39/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1425e-04 - val_loss: 4.5702e-05\n",
      "Epoch 40/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1403e-04 - val_loss: 2.7125e-04\n",
      "Epoch 41/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0629e-04 - val_loss: 1.9131e-04\n",
      "Epoch 42/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1256e-04 - val_loss: 2.2460e-05\n",
      "Epoch 43/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1529e-04 - val_loss: 1.0622e-04\n",
      "Epoch 44/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0690e-04 - val_loss: 1.4060e-05\n",
      "Epoch 45/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1654e-04 - val_loss: 5.9668e-05\n",
      "Epoch 46/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1398e-04 - val_loss: 2.4185e-05\n",
      "Epoch 47/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0776e-04 - val_loss: 8.9509e-05\n",
      "Epoch 48/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2559e-04 - val_loss: 1.5302e-04\n",
      "Epoch 49/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0932e-04 - val_loss: 4.5355e-05\n",
      "Epoch 50/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0835e-04 - val_loss: 2.2021e-05\n",
      "Epoch 51/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1301e-04 - val_loss: 6.2531e-05\n",
      "Epoch 52/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1039e-04 - val_loss: 8.4840e-05\n",
      "Epoch 53/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1492e-04 - val_loss: 2.4803e-05\n",
      "Epoch 54/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1298e-04 - val_loss: 2.0600e-04\n",
      "Epoch 55/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0371e-04 - val_loss: 3.9428e-05\n",
      "Epoch 56/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1211e-04 - val_loss: 5.7441e-05\n",
      "Epoch 57/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1391e-04 - val_loss: 2.5043e-05\n",
      "Epoch 58/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1101e-04 - val_loss: 3.1484e-05\n",
      "Epoch 59/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1986e-04 - val_loss: 1.9169e-05\n",
      "Epoch 60/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1266e-04 - val_loss: 3.8465e-05\n",
      "Epoch 61/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 1.0920e-04 - val_loss: 6.3456e-05\n",
      "Epoch 62/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0574e-04 - val_loss: 1.4816e-05\n",
      "Epoch 63/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1310e-04 - val_loss: 1.5683e-05\n",
      "Epoch 64/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0689e-04 - val_loss: 1.8081e-04\n",
      "Epoch 65/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1480e-04 - val_loss: 1.4018e-05\n",
      "Epoch 66/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0976e-04 - val_loss: 3.1206e-04\n",
      "Epoch 67/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 9.9306e-05 - val_loss: 3.9276e-05\n",
      "Epoch 68/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1780e-04 - val_loss: 2.0030e-05\n",
      "Epoch 69/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1875e-04 - val_loss: 1.2612e-04\n",
      "Epoch 70/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0692e-04 - val_loss: 2.1996e-05\n",
      "Epoch 71/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0088e-04 - val_loss: 4.0845e-05\n",
      "Epoch 72/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0097e-04 - val_loss: 2.7385e-05\n",
      "Epoch 73/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1405e-04 - val_loss: 7.3846e-05\n",
      "Epoch 74/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0590e-04 - val_loss: 6.7238e-05\n",
      "Epoch 75/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1538e-04 - val_loss: 1.3555e-05\n",
      "Epoch 76/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0637e-04 - val_loss: 2.1299e-05\n",
      "Epoch 77/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0651e-04 - val_loss: 4.9939e-05\n",
      "Epoch 78/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0265e-04 - val_loss: 1.5862e-05\n",
      "Epoch 79/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0555e-04 - val_loss: 3.3001e-05\n",
      "Epoch 80/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1155e-04 - val_loss: 1.9682e-05\n",
      "Epoch 81/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0347e-04 - val_loss: 1.7006e-04\n",
      "2081/2081 [==============================] - 1s 709us/step - loss: 0.0011\n",
      "Epoch 1/81\n",
      "2081/2081 [==============================] - 5s 2ms/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 2/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0019 - val_loss: 7.6395e-04\n",
      "Epoch 3/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0011 - val_loss: 2.7904e-04\n",
      "Epoch 4/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 7.9220e-04 - val_loss: 1.8064e-05\n",
      "Epoch 5/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 5.9282e-04 - val_loss: 4.5546e-04\n",
      "Epoch 6/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 4.2819e-04 - val_loss: 7.4226e-05\n",
      "Epoch 7/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.3321e-04 - val_loss: 9.2250e-04\n",
      "Epoch 8/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.3305e-04 - val_loss: 0.0011\n",
      "Epoch 9/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.3906e-04 - val_loss: 9.0045e-04\n",
      "Epoch 10/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.0804e-04 - val_loss: 2.5017e-04\n",
      "Epoch 11/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8671e-04 - val_loss: 2.9399e-05\n",
      "Epoch 12/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6967e-04 - val_loss: 2.2441e-05\n",
      "Epoch 13/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7312e-04 - val_loss: 6.0618e-04\n",
      "Epoch 14/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.0868e-04 - val_loss: 1.3296e-04\n",
      "Epoch 15/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.9019e-04 - val_loss: 6.7038e-04\n",
      "Epoch 16/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8174e-04 - val_loss: 8.5297e-05\n",
      "Epoch 17/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7696e-04 - val_loss: 5.8065e-05\n",
      "Epoch 18/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7608e-04 - val_loss: 3.1667e-04\n",
      "Epoch 19/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.0048e-04 - val_loss: 4.1574e-04\n",
      "Epoch 20/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8637e-04 - val_loss: 2.5813e-05\n",
      "Epoch 21/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7016e-04 - val_loss: 2.8609e-04\n",
      "Epoch 22/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6445e-04 - val_loss: 2.4497e-04\n",
      "Epoch 23/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7069e-04 - val_loss: 2.9153e-05\n",
      "Epoch 24/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5908e-04 - val_loss: 0.0014\n",
      "Epoch 25/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5393e-04 - val_loss: 9.5016e-04\n",
      "Epoch 26/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6608e-04 - val_loss: 4.1389e-04\n",
      "Epoch 27/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5610e-04 - val_loss: 5.2763e-05\n",
      "Epoch 28/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5845e-04 - val_loss: 9.6371e-05\n",
      "Epoch 29/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7204e-04 - val_loss: 1.6784e-05\n",
      "Epoch 30/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6996e-04 - val_loss: 6.8045e-05\n",
      "Epoch 31/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4507e-04 - val_loss: 5.7106e-04\n",
      "Epoch 32/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5474e-04 - val_loss: 2.7020e-04\n",
      "Epoch 33/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5724e-04 - val_loss: 3.0566e-04\n",
      "Epoch 34/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3451e-04 - val_loss: 3.6120e-04\n",
      "Epoch 35/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5017e-04 - val_loss: 2.7398e-04\n",
      "Epoch 36/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5735e-04 - val_loss: 1.5232e-05\n",
      "Epoch 37/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3687e-04 - val_loss: 0.0011\n",
      "Epoch 38/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5174e-04 - val_loss: 1.0921e-04\n",
      "Epoch 39/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3619e-04 - val_loss: 9.2291e-04\n",
      "Epoch 40/81\n",
      "2081/2081 [==============================] - 3s 2ms/step - loss: 2.7738e-04 - val_loss: 3.5969e-05\n",
      "Epoch 41/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5491e-04 - val_loss: 5.9698e-04\n",
      "Epoch 42/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6768e-04 - val_loss: 9.5822e-04\n",
      "Epoch 43/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3914e-04 - val_loss: 1.1772e-04\n",
      "Epoch 44/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3604e-04 - val_loss: 7.5310e-04\n",
      "Epoch 45/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5895e-04 - val_loss: 7.0786e-04\n",
      "Epoch 46/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5852e-04 - val_loss: 0.0018\n",
      "Epoch 47/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3960e-04 - val_loss: 0.0012\n",
      "Epoch 48/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6206e-04 - val_loss: 3.6843e-04\n",
      "Epoch 49/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4457e-04 - val_loss: 1.5987e-04\n",
      "Epoch 50/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4823e-04 - val_loss: 0.0013\n",
      "Epoch 51/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5968e-04 - val_loss: 9.1775e-04\n",
      "Epoch 52/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4574e-04 - val_loss: 1.5385e-04\n",
      "Epoch 53/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4082e-04 - val_loss: 1.0093e-04\n",
      "Epoch 54/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5921e-04 - val_loss: 5.1499e-05\n",
      "Epoch 55/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2965e-04 - val_loss: 2.1087e-04\n",
      "Epoch 56/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3805e-04 - val_loss: 5.7416e-04\n",
      "Epoch 57/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5037e-04 - val_loss: 6.5088e-04\n",
      "Epoch 58/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6655e-04 - val_loss: 8.3173e-04\n",
      "Epoch 59/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5672e-04 - val_loss: 4.7385e-05\n",
      "Epoch 60/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4289e-04 - val_loss: 7.1654e-05\n",
      "Epoch 61/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3260e-04 - val_loss: 4.7226e-05\n",
      "Epoch 62/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4893e-04 - val_loss: 2.6617e-05\n",
      "Epoch 63/81\n",
      "2081/2081 [==============================] - 3s 2ms/step - loss: 2.6113e-04 - val_loss: 6.3164e-04\n",
      "Epoch 64/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4539e-04 - val_loss: 2.5764e-05\n",
      "Epoch 65/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8809e-04 - val_loss: 2.9282e-04\n",
      "Epoch 66/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2988e-04 - val_loss: 1.7633e-04\n",
      "Epoch 67/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2535e-04 - val_loss: 2.9745e-04\n",
      "Epoch 68/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4465e-04 - val_loss: 7.8583e-04\n",
      "Epoch 69/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2373e-04 - val_loss: 2.9686e-04\n",
      "Epoch 70/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5592e-04 - val_loss: 7.8818e-04\n",
      "Epoch 71/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3494e-04 - val_loss: 2.4619e-04\n",
      "Epoch 72/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4583e-04 - val_loss: 4.8990e-04\n",
      "Epoch 73/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2388e-04 - val_loss: 6.6866e-05\n",
      "Epoch 74/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3343e-04 - val_loss: 6.6356e-05\n",
      "Epoch 75/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5956e-04 - val_loss: 8.1481e-05\n",
      "Epoch 76/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2752e-04 - val_loss: 2.2112e-04\n",
      "Epoch 77/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2326e-04 - val_loss: 6.1129e-04\n",
      "Epoch 78/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3178e-04 - val_loss: 1.3205e-04\n",
      "Epoch 79/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3566e-04 - val_loss: 8.0778e-05\n",
      "Epoch 80/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3177e-04 - val_loss: 4.8704e-05\n",
      "Epoch 81/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4456e-04 - val_loss: 4.5938e-04\n",
      "2080/2080 [==============================] - 1s 694us/step - loss: 1.3476e-04\n",
      "Epoch 1/81\n",
      "2080/2080 [==============================] - 5s 2ms/step - loss: 0.1325 - val_loss: 0.0190\n",
      "Epoch 2/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.1219 - val_loss: 0.0162\n",
      "Epoch 3/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.1118 - val_loss: 0.0138\n",
      "Epoch 4/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 0.1022 - val_loss: 0.0118\n",
      "Epoch 5/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0932 - val_loss: 0.0101\n",
      "Epoch 6/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0846 - val_loss: 0.0088\n",
      "Epoch 7/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0766 - val_loss: 0.0078\n",
      "Epoch 8/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0691 - val_loss: 0.0071\n",
      "Epoch 9/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0619 - val_loss: 0.0067\n",
      "Epoch 10/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0553 - val_loss: 0.0067\n",
      "Epoch 11/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0488 - val_loss: 0.0070\n",
      "Epoch 12/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0432 - val_loss: 0.0075\n",
      "Epoch 13/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0381 - val_loss: 0.0083\n",
      "Epoch 14/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0331 - val_loss: 0.0094\n",
      "Epoch 15/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0290 - val_loss: 0.0107\n",
      "Epoch 16/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0250 - val_loss: 0.0122\n",
      "Epoch 17/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0218 - val_loss: 0.0139\n",
      "Epoch 18/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0187 - val_loss: 0.0156\n",
      "Epoch 19/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 20/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0143 - val_loss: 0.0194\n",
      "Epoch 21/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0127 - val_loss: 0.0214\n",
      "Epoch 22/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0113 - val_loss: 0.0233\n",
      "Epoch 23/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0251\n",
      "Epoch 24/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0267\n",
      "Epoch 25/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0086 - val_loss: 0.0282\n",
      "Epoch 26/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0081 - val_loss: 0.0295\n",
      "Epoch 27/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0076 - val_loss: 0.0306\n",
      "Epoch 28/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0075 - val_loss: 0.0315\n",
      "Epoch 29/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0071 - val_loss: 0.0322\n",
      "Epoch 30/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0071 - val_loss: 0.0327\n",
      "Epoch 31/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0071 - val_loss: 0.0331\n",
      "Epoch 32/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0070 - val_loss: 0.0334\n",
      "Epoch 33/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0069 - val_loss: 0.0336\n",
      "Epoch 34/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0069 - val_loss: 0.0338\n",
      "Epoch 35/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0068 - val_loss: 0.0339\n",
      "Epoch 36/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0066 - val_loss: 0.0339\n",
      "Epoch 37/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 0.0066 - val_loss: 0.0338\n",
      "Epoch 38/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0066 - val_loss: 0.0337\n",
      "Epoch 39/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0065 - val_loss: 0.0336\n",
      "Epoch 40/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0065 - val_loss: 0.0334\n",
      "Epoch 41/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0063 - val_loss: 0.0333\n",
      "Epoch 42/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0064 - val_loss: 0.0331\n",
      "Epoch 43/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0063 - val_loss: 0.0329\n",
      "Epoch 44/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0063 - val_loss: 0.0327\n",
      "Epoch 45/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0062 - val_loss: 0.0324\n",
      "Epoch 46/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0061 - val_loss: 0.0323\n",
      "Epoch 47/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0060 - val_loss: 0.0320\n",
      "Epoch 48/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0061 - val_loss: 0.0317\n",
      "Epoch 49/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0059 - val_loss: 0.0315\n",
      "Epoch 50/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0058 - val_loss: 0.0313\n",
      "Epoch 51/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0058 - val_loss: 0.0311\n",
      "Epoch 52/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0058 - val_loss: 0.0308\n",
      "Epoch 53/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0058 - val_loss: 0.0306\n",
      "Epoch 54/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0058 - val_loss: 0.0303\n",
      "Epoch 55/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 0.0058 - val_loss: 0.0302\n",
      "Epoch 56/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0054 - val_loss: 0.0299\n",
      "Epoch 57/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0055 - val_loss: 0.0297\n",
      "Epoch 58/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0055 - val_loss: 0.0295\n",
      "Epoch 59/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 0.0055 - val_loss: 0.0292\n",
      "Epoch 60/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0053 - val_loss: 0.0290\n",
      "Epoch 61/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0052 - val_loss: 0.0288\n",
      "Epoch 62/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0053 - val_loss: 0.0286\n",
      "Epoch 63/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0052 - val_loss: 0.0283\n",
      "Epoch 64/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0052 - val_loss: 0.0281\n",
      "Epoch 65/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0052 - val_loss: 0.0279\n",
      "Epoch 66/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0277\n",
      "Epoch 67/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0274\n",
      "Epoch 68/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0272\n",
      "Epoch 69/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0269\n",
      "Epoch 70/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0267\n",
      "Epoch 71/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0048 - val_loss: 0.0265\n",
      "Epoch 72/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0047 - val_loss: 0.0263\n",
      "Epoch 73/81\n",
      "2080/2080 [==============================] - 3s 2ms/step - loss: 0.0047 - val_loss: 0.0260\n",
      "Epoch 74/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0048 - val_loss: 0.0258\n",
      "Epoch 75/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0047 - val_loss: 0.0256\n",
      "Epoch 76/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0047 - val_loss: 0.0253\n",
      "Epoch 77/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0046 - val_loss: 0.0251\n",
      "Epoch 78/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0045 - val_loss: 0.0249\n",
      "Epoch 79/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0045 - val_loss: 0.0247\n",
      "Epoch 80/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0044 - val_loss: 0.0244\n",
      "Epoch 81/81\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0044 - val_loss: 0.0242\n",
      "2081/2081 [==============================] - 1s 668us/step - loss: 0.0340\n",
      "Epoch 1/81\n",
      "2081/2081 [==============================] - 5s 2ms/step - loss: 0.3355 - val_loss: 0.0191\n",
      "Epoch 2/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.3170 - val_loss: 0.0163\n",
      "Epoch 3/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2981 - val_loss: 0.0138\n",
      "Epoch 4/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2795 - val_loss: 0.0116\n",
      "Epoch 5/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2608 - val_loss: 0.0098\n",
      "Epoch 6/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2427 - val_loss: 0.0083\n",
      "Epoch 7/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2242 - val_loss: 0.0073\n",
      "Epoch 8/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2064 - val_loss: 0.0067\n",
      "Epoch 9/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1888 - val_loss: 0.0066\n",
      "Epoch 10/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1715 - val_loss: 0.0070\n",
      "Epoch 11/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1539 - val_loss: 0.0079\n",
      "Epoch 12/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1378 - val_loss: 0.0093\n",
      "Epoch 13/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1217 - val_loss: 0.0114\n",
      "Epoch 14/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1066 - val_loss: 0.0139\n",
      "Epoch 15/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0926 - val_loss: 0.0170\n",
      "Epoch 16/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0798 - val_loss: 0.0207\n",
      "Epoch 17/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0679 - val_loss: 0.0247\n",
      "Epoch 18/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0575 - val_loss: 0.0293\n",
      "Epoch 19/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0483 - val_loss: 0.0340\n",
      "Epoch 20/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0403 - val_loss: 0.0389\n",
      "Epoch 21/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0336 - val_loss: 0.0439\n",
      "Epoch 22/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0285 - val_loss: 0.0488\n",
      "Epoch 23/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0236 - val_loss: 0.0534\n",
      "Epoch 24/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0204 - val_loss: 0.0578\n",
      "Epoch 25/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0176 - val_loss: 0.0618\n",
      "Epoch 26/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0160 - val_loss: 0.0653\n",
      "Epoch 27/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0147 - val_loss: 0.0684\n",
      "Epoch 28/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0131 - val_loss: 0.0710\n",
      "Epoch 29/81\n",
      "2081/2081 [==============================] - 3s 2ms/step - loss: 0.0127 - val_loss: 0.0731\n",
      "Epoch 30/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0120 - val_loss: 0.0750\n",
      "Epoch 31/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0114 - val_loss: 0.0765\n",
      "Epoch 32/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0114 - val_loss: 0.0776\n",
      "Epoch 33/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0111 - val_loss: 0.0786\n",
      "Epoch 34/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0109 - val_loss: 0.0792\n",
      "Epoch 35/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0111 - val_loss: 0.0798\n",
      "Epoch 36/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0105 - val_loss: 0.0801\n",
      "Epoch 37/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0104 - val_loss: 0.0803\n",
      "Epoch 38/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0105 - val_loss: 0.0803\n",
      "Epoch 39/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0108 - val_loss: 0.0803\n",
      "Epoch 40/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0104 - val_loss: 0.0803\n",
      "Epoch 41/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0802\n",
      "Epoch 42/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0106 - val_loss: 0.0800\n",
      "Epoch 43/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0106 - val_loss: 0.0798\n",
      "Epoch 44/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0103 - val_loss: 0.0796\n",
      "Epoch 45/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0794\n",
      "Epoch 46/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0109 - val_loss: 0.0792\n",
      "Epoch 47/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0101 - val_loss: 0.0788\n",
      "Epoch 48/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0104 - val_loss: 0.0786\n",
      "Epoch 49/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0101 - val_loss: 0.0782\n",
      "Epoch 50/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0101 - val_loss: 0.0779\n",
      "Epoch 51/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0100 - val_loss: 0.0776\n",
      "Epoch 52/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0773\n",
      "Epoch 53/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0101 - val_loss: 0.0770\n",
      "Epoch 54/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0101 - val_loss: 0.0766\n",
      "Epoch 55/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0100 - val_loss: 0.0764\n",
      "Epoch 56/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0098 - val_loss: 0.0760\n",
      "Epoch 57/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0100 - val_loss: 0.0757\n",
      "Epoch 58/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0098 - val_loss: 0.0754\n",
      "Epoch 59/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0099 - val_loss: 0.0750\n",
      "Epoch 60/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0098 - val_loss: 0.0747\n",
      "Epoch 61/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0100 - val_loss: 0.0745\n",
      "Epoch 62/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0097 - val_loss: 0.0742\n",
      "Epoch 63/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0096 - val_loss: 0.0738\n",
      "Epoch 64/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0099 - val_loss: 0.0734\n",
      "Epoch 65/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0097 - val_loss: 0.0731\n",
      "Epoch 66/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0095 - val_loss: 0.0729\n",
      "Epoch 67/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0096 - val_loss: 0.0726\n",
      "Epoch 68/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0094 - val_loss: 0.0723\n",
      "Epoch 69/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0094 - val_loss: 0.0720\n",
      "Epoch 70/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0094 - val_loss: 0.0717\n",
      "Epoch 71/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0092 - val_loss: 0.0713\n",
      "Epoch 72/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0094 - val_loss: 0.0710\n",
      "Epoch 73/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0705\n",
      "Epoch 74/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0702\n",
      "Epoch 75/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0090 - val_loss: 0.0698\n",
      "Epoch 76/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0694\n",
      "Epoch 77/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0691\n",
      "Epoch 78/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0090 - val_loss: 0.0688\n",
      "Epoch 79/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0089 - val_loss: 0.0684\n",
      "Epoch 80/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0090 - val_loss: 0.0681\n",
      "Epoch 81/81\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0089 - val_loss: 0.0679\n",
      "2080/2080 [==============================] - 1s 608us/step - loss: 0.0221\n",
      "Epoch 1/82\n",
      "2080/2080 [==============================] - 5s 2ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 2/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 5.9878e-04 - val_loss: 7.8652e-04\n",
      "Epoch 3/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 3.4818e-04 - val_loss: 0.0015\n",
      "Epoch 4/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 2.4002e-04 - val_loss: 4.1038e-04\n",
      "Epoch 5/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.7666e-04 - val_loss: 6.8098e-04\n",
      "Epoch 6/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.5502e-04 - val_loss: 0.0013\n",
      "Epoch 7/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.4971e-04 - val_loss: 5.2076e-04\n",
      "Epoch 8/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.4139e-04 - val_loss: 1.3404e-04\n",
      "Epoch 9/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3706e-04 - val_loss: 3.3382e-04\n",
      "Epoch 10/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.4137e-04 - val_loss: 2.7827e-05\n",
      "Epoch 11/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3044e-04 - val_loss: 1.7113e-04\n",
      "Epoch 12/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3333e-04 - val_loss: 3.8770e-04\n",
      "Epoch 13/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.4512e-04 - val_loss: 2.1695e-05\n",
      "Epoch 14/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3031e-04 - val_loss: 1.4421e-04\n",
      "Epoch 15/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1416e-04 - val_loss: 2.9343e-04\n",
      "Epoch 16/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2908e-04 - val_loss: 6.2101e-05\n",
      "Epoch 17/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.3084e-04 - val_loss: 7.7269e-05\n",
      "Epoch 18/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2756e-04 - val_loss: 1.6893e-04\n",
      "Epoch 19/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2361e-04 - val_loss: 1.4467e-05\n",
      "Epoch 20/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1829e-04 - val_loss: 2.4769e-04\n",
      "Epoch 21/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1515e-04 - val_loss: 6.5248e-05\n",
      "Epoch 22/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1950e-04 - val_loss: 4.5267e-05\n",
      "Epoch 23/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1896e-04 - val_loss: 1.7236e-04\n",
      "Epoch 24/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2184e-04 - val_loss: 5.0449e-05\n",
      "Epoch 25/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1384e-04 - val_loss: 3.1719e-04\n",
      "Epoch 26/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0547e-04 - val_loss: 1.8009e-04\n",
      "Epoch 27/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1475e-04 - val_loss: 1.8894e-05\n",
      "Epoch 28/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2159e-04 - val_loss: 1.0890e-04\n",
      "Epoch 29/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2606e-04 - val_loss: 5.0050e-05\n",
      "Epoch 30/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1377e-04 - val_loss: 5.3704e-04\n",
      "Epoch 31/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1484e-04 - val_loss: 1.8660e-04\n",
      "Epoch 32/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1571e-04 - val_loss: 1.9457e-04\n",
      "Epoch 33/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0597e-04 - val_loss: 3.2163e-04\n",
      "Epoch 34/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1511e-04 - val_loss: 1.8696e-04\n",
      "Epoch 35/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2688e-04 - val_loss: 4.3126e-04\n",
      "Epoch 36/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1229e-04 - val_loss: 1.2193e-04\n",
      "Epoch 37/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1431e-04 - val_loss: 1.7007e-05\n",
      "Epoch 38/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1301e-04 - val_loss: 6.4855e-05\n",
      "Epoch 39/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1807e-04 - val_loss: 2.5326e-05\n",
      "Epoch 40/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1799e-04 - val_loss: 2.7725e-05\n",
      "Epoch 41/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1710e-04 - val_loss: 2.5285e-05\n",
      "Epoch 42/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1129e-04 - val_loss: 1.8606e-05\n",
      "Epoch 43/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1969e-04 - val_loss: 1.4833e-04\n",
      "Epoch 44/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0576e-04 - val_loss: 1.9853e-04\n",
      "Epoch 45/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1232e-04 - val_loss: 2.3308e-05\n",
      "Epoch 46/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0421e-04 - val_loss: 1.2435e-04\n",
      "Epoch 47/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1405e-04 - val_loss: 1.1551e-04\n",
      "Epoch 48/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.2422e-04 - val_loss: 1.6064e-05\n",
      "Epoch 49/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0825e-04 - val_loss: 4.5421e-05\n",
      "Epoch 50/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1272e-04 - val_loss: 1.9643e-04\n",
      "Epoch 51/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1266e-04 - val_loss: 1.3408e-04\n",
      "Epoch 52/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1056e-04 - val_loss: 2.7785e-04\n",
      "Epoch 53/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0606e-04 - val_loss: 3.5981e-05\n",
      "Epoch 54/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1853e-04 - val_loss: 1.1253e-04\n",
      "Epoch 55/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1082e-04 - val_loss: 1.4970e-04\n",
      "Epoch 56/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0847e-04 - val_loss: 1.4185e-04\n",
      "Epoch 57/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1149e-04 - val_loss: 4.5915e-05\n",
      "Epoch 58/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0721e-04 - val_loss: 2.8613e-05\n",
      "Epoch 59/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0896e-04 - val_loss: 2.2317e-05\n",
      "Epoch 60/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1950e-04 - val_loss: 2.1440e-05\n",
      "Epoch 61/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1860e-04 - val_loss: 2.2233e-05\n",
      "Epoch 62/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0644e-04 - val_loss: 3.0138e-05\n",
      "Epoch 63/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0795e-04 - val_loss: 6.8225e-05\n",
      "Epoch 64/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0305e-04 - val_loss: 2.3447e-05\n",
      "Epoch 65/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0822e-04 - val_loss: 1.2883e-04\n",
      "Epoch 66/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0384e-04 - val_loss: 1.0751e-04\n",
      "Epoch 67/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0888e-04 - val_loss: 6.4952e-05\n",
      "Epoch 68/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0735e-04 - val_loss: 1.5301e-04\n",
      "Epoch 69/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0261e-04 - val_loss: 2.0339e-05\n",
      "Epoch 70/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1022e-04 - val_loss: 6.1081e-05\n",
      "Epoch 71/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 9.7253e-05 - val_loss: 1.0679e-04\n",
      "Epoch 72/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1368e-04 - val_loss: 5.8770e-05\n",
      "Epoch 73/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1387e-04 - val_loss: 5.7117e-05\n",
      "Epoch 74/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0072e-04 - val_loss: 9.2199e-05\n",
      "Epoch 75/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1836e-04 - val_loss: 1.1327e-04\n",
      "Epoch 76/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 9.7343e-05 - val_loss: 2.5637e-05\n",
      "Epoch 77/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0499e-04 - val_loss: 1.6432e-04\n",
      "Epoch 78/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0844e-04 - val_loss: 1.0146e-04\n",
      "Epoch 79/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0870e-04 - val_loss: 1.9263e-04\n",
      "Epoch 80/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.1068e-04 - val_loss: 4.0691e-05\n",
      "Epoch 81/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0608e-04 - val_loss: 7.7452e-05\n",
      "Epoch 82/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 1.0120e-04 - val_loss: 3.7034e-05\n",
      "2081/2081 [==============================] - 1s 632us/step - loss: 0.0019\n",
      "Epoch 1/82\n",
      "2081/2081 [==============================] - 5s 2ms/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 2/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 3/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 4/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 8.0235e-04 - val_loss: 8.1518e-05\n",
      "Epoch 5/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 5.6851e-04 - val_loss: 1.6348e-04\n",
      "Epoch 6/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.8737e-04 - val_loss: 0.0013\n",
      "Epoch 7/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.3284e-04 - val_loss: 0.0010\n",
      "Epoch 8/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.2873e-04 - val_loss: 4.4979e-04\n",
      "Epoch 9/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.5291e-04 - val_loss: 0.0016\n",
      "Epoch 10/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.2866e-04 - val_loss: 2.2299e-05\n",
      "Epoch 11/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.0715e-04 - val_loss: 5.3655e-05\n",
      "Epoch 12/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.9779e-04 - val_loss: 3.7590e-05\n",
      "Epoch 13/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.9167e-04 - val_loss: 8.4696e-04\n",
      "Epoch 14/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8830e-04 - val_loss: 1.7207e-04\n",
      "Epoch 15/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7191e-04 - val_loss: 6.0773e-04\n",
      "Epoch 16/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6299e-04 - val_loss: 1.0744e-04\n",
      "Epoch 17/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8441e-04 - val_loss: 2.1778e-04\n",
      "Epoch 18/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6990e-04 - val_loss: 1.2998e-04\n",
      "Epoch 19/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6228e-04 - val_loss: 5.5896e-05\n",
      "Epoch 20/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5055e-04 - val_loss: 6.6025e-05\n",
      "Epoch 21/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7134e-04 - val_loss: 3.3525e-04\n",
      "Epoch 22/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8499e-04 - val_loss: 7.3627e-04\n",
      "Epoch 23/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8419e-04 - val_loss: 6.8536e-05\n",
      "Epoch 24/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7264e-04 - val_loss: 4.6618e-04\n",
      "Epoch 25/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 3.0262e-04 - val_loss: 7.6526e-04\n",
      "Epoch 26/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6837e-04 - val_loss: 1.8096e-04\n",
      "Epoch 27/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6117e-04 - val_loss: 4.2750e-05\n",
      "Epoch 28/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.9986e-04 - val_loss: 3.7705e-04\n",
      "Epoch 29/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6150e-04 - val_loss: 4.1171e-04\n",
      "Epoch 30/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4961e-04 - val_loss: 1.0829e-04\n",
      "Epoch 31/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5805e-04 - val_loss: 6.0244e-04\n",
      "Epoch 32/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4246e-04 - val_loss: 2.5836e-04\n",
      "Epoch 33/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4794e-04 - val_loss: 7.0458e-05\n",
      "Epoch 34/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.8827e-04 - val_loss: 3.9778e-04\n",
      "Epoch 35/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5244e-04 - val_loss: 6.3818e-04\n",
      "Epoch 36/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6244e-04 - val_loss: 6.9563e-04\n",
      "Epoch 37/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4266e-04 - val_loss: 5.9007e-04\n",
      "Epoch 38/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7524e-04 - val_loss: 2.7896e-04\n",
      "Epoch 39/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6960e-04 - val_loss: 3.9554e-04\n",
      "Epoch 40/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3810e-04 - val_loss: 2.5997e-04\n",
      "Epoch 41/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3452e-04 - val_loss: 1.1074e-04\n",
      "Epoch 42/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3473e-04 - val_loss: 4.2402e-05\n",
      "Epoch 43/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6988e-04 - val_loss: 2.3468e-04\n",
      "Epoch 44/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3792e-04 - val_loss: 3.8607e-04\n",
      "Epoch 45/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.6521e-04 - val_loss: 1.8972e-04\n",
      "Epoch 46/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2262e-04 - val_loss: 5.5091e-05\n",
      "Epoch 47/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5019e-04 - val_loss: 2.2962e-04\n",
      "Epoch 48/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5587e-04 - val_loss: 7.3889e-05\n",
      "Epoch 49/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4855e-04 - val_loss: 0.0017\n",
      "Epoch 50/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5522e-04 - val_loss: 5.4602e-05\n",
      "Epoch 51/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5141e-04 - val_loss: 2.1104e-04\n",
      "Epoch 52/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5416e-04 - val_loss: 3.5987e-04\n",
      "Epoch 53/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3941e-04 - val_loss: 2.1557e-04\n",
      "Epoch 54/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4315e-04 - val_loss: 5.0548e-04\n",
      "Epoch 55/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.1972e-04 - val_loss: 2.6320e-05\n",
      "Epoch 56/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.9420e-04 - val_loss: 3.3458e-04\n",
      "Epoch 57/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5476e-04 - val_loss: 5.8099e-05\n",
      "Epoch 58/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4454e-04 - val_loss: 3.9287e-04\n",
      "Epoch 59/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7411e-04 - val_loss: 1.8489e-04\n",
      "Epoch 60/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2322e-04 - val_loss: 1.4590e-04\n",
      "Epoch 61/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3302e-04 - val_loss: 2.0283e-04\n",
      "Epoch 62/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4732e-04 - val_loss: 3.0625e-05\n",
      "Epoch 63/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3610e-04 - val_loss: 3.3913e-04\n",
      "Epoch 64/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.1556e-04 - val_loss: 1.1152e-04\n",
      "Epoch 65/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2916e-04 - val_loss: 4.8942e-05\n",
      "Epoch 66/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.1486e-04 - val_loss: 1.2863e-04\n",
      "Epoch 67/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3341e-04 - val_loss: 5.8565e-04\n",
      "Epoch 68/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4911e-04 - val_loss: 4.9263e-04\n",
      "Epoch 69/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4113e-04 - val_loss: 0.0019\n",
      "Epoch 70/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4808e-04 - val_loss: 7.9575e-05\n",
      "Epoch 71/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5012e-04 - val_loss: 3.0619e-05\n",
      "Epoch 72/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4428e-04 - val_loss: 4.2162e-04\n",
      "Epoch 73/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3837e-04 - val_loss: 5.7564e-05\n",
      "Epoch 74/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.1120e-04 - val_loss: 2.6116e-04\n",
      "Epoch 75/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.7596e-04 - val_loss: 4.3539e-04\n",
      "Epoch 76/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3980e-04 - val_loss: 8.7919e-05\n",
      "Epoch 77/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4922e-04 - val_loss: 6.5747e-04\n",
      "Epoch 78/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3163e-04 - val_loss: 1.3370e-04\n",
      "Epoch 79/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.3613e-04 - val_loss: 7.2339e-05\n",
      "Epoch 80/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.4645e-04 - val_loss: 4.3872e-05\n",
      "Epoch 81/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.2620e-04 - val_loss: 4.5260e-04\n",
      "Epoch 82/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 2.5199e-04 - val_loss: 1.0827e-04\n",
      "2080/2080 [==============================] - 1s 612us/step - loss: 1.6883e-04\n",
      "Epoch 1/82\n",
      "2080/2080 [==============================] - 5s 2ms/step - loss: 0.1317 - val_loss: 0.0188\n",
      "Epoch 2/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.1217 - val_loss: 0.0162\n",
      "Epoch 3/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.1122 - val_loss: 0.0138\n",
      "Epoch 4/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.1030 - val_loss: 0.0119\n",
      "Epoch 5/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0942 - val_loss: 0.0102\n",
      "Epoch 6/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0858 - val_loss: 0.0089\n",
      "Epoch 7/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0782 - val_loss: 0.0079\n",
      "Epoch 8/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0704 - val_loss: 0.0072\n",
      "Epoch 9/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0637 - val_loss: 0.0069\n",
      "Epoch 10/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0570 - val_loss: 0.0069\n",
      "Epoch 11/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0510 - val_loss: 0.0071\n",
      "Epoch 12/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0453 - val_loss: 0.0076\n",
      "Epoch 13/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0400 - val_loss: 0.0085\n",
      "Epoch 14/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0352 - val_loss: 0.0095\n",
      "Epoch 15/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0309 - val_loss: 0.0108\n",
      "Epoch 16/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0271 - val_loss: 0.0123\n",
      "Epoch 17/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0235 - val_loss: 0.0139\n",
      "Epoch 18/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0206 - val_loss: 0.0157\n",
      "Epoch 19/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0181 - val_loss: 0.0176\n",
      "Epoch 20/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0159 - val_loss: 0.0196\n",
      "Epoch 21/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0140 - val_loss: 0.0216\n",
      "Epoch 22/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0125 - val_loss: 0.0235\n",
      "Epoch 23/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0113 - val_loss: 0.0254\n",
      "Epoch 24/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0103 - val_loss: 0.0272\n",
      "Epoch 25/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0096 - val_loss: 0.0288\n",
      "Epoch 26/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0303\n",
      "Epoch 27/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0086 - val_loss: 0.0316\n",
      "Epoch 28/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0083 - val_loss: 0.0326\n",
      "Epoch 29/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0080 - val_loss: 0.0335\n",
      "Epoch 30/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0078 - val_loss: 0.0342\n",
      "Epoch 31/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0076 - val_loss: 0.0348\n",
      "Epoch 32/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0076 - val_loss: 0.0352\n",
      "Epoch 33/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0075 - val_loss: 0.0355\n",
      "Epoch 34/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0076 - val_loss: 0.0357\n",
      "Epoch 35/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0074 - val_loss: 0.0358\n",
      "Epoch 36/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0073 - val_loss: 0.0358\n",
      "Epoch 37/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0073 - val_loss: 0.0358\n",
      "Epoch 38/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0358\n",
      "Epoch 39/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0073 - val_loss: 0.0358\n",
      "Epoch 40/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0072 - val_loss: 0.0357\n",
      "Epoch 41/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0071 - val_loss: 0.0356\n",
      "Epoch 42/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0071 - val_loss: 0.0355\n",
      "Epoch 43/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0071 - val_loss: 0.0353\n",
      "Epoch 44/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0070 - val_loss: 0.0351\n",
      "Epoch 45/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0067 - val_loss: 0.0349\n",
      "Epoch 46/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0068 - val_loss: 0.0347\n",
      "Epoch 47/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0067 - val_loss: 0.0345\n",
      "Epoch 48/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0067 - val_loss: 0.0343\n",
      "Epoch 49/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0066 - val_loss: 0.0340\n",
      "Epoch 50/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0065 - val_loss: 0.0338\n",
      "Epoch 51/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0065 - val_loss: 0.0336\n",
      "Epoch 52/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0066 - val_loss: 0.0334\n",
      "Epoch 53/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0065 - val_loss: 0.0332\n",
      "Epoch 54/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0065 - val_loss: 0.0330\n",
      "Epoch 55/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0063 - val_loss: 0.0327\n",
      "Epoch 56/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0062 - val_loss: 0.0324\n",
      "Epoch 57/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0063 - val_loss: 0.0323\n",
      "Epoch 58/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0062 - val_loss: 0.0321\n",
      "Epoch 59/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0060 - val_loss: 0.0318\n",
      "Epoch 60/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0061 - val_loss: 0.0316\n",
      "Epoch 61/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0060 - val_loss: 0.0314\n",
      "Epoch 62/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0059 - val_loss: 0.0311\n",
      "Epoch 63/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0058 - val_loss: 0.0308\n",
      "Epoch 64/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0060 - val_loss: 0.0306\n",
      "Epoch 65/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0057 - val_loss: 0.0304\n",
      "Epoch 66/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0059 - val_loss: 0.0302\n",
      "Epoch 67/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0056 - val_loss: 0.0299\n",
      "Epoch 68/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0057 - val_loss: 0.0297\n",
      "Epoch 69/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0055 - val_loss: 0.0294\n",
      "Epoch 70/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0055 - val_loss: 0.0292\n",
      "Epoch 71/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0055 - val_loss: 0.0290\n",
      "Epoch 72/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0054 - val_loss: 0.0288\n",
      "Epoch 73/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0055 - val_loss: 0.0286\n",
      "Epoch 74/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0054 - val_loss: 0.0284\n",
      "Epoch 75/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0054 - val_loss: 0.0281\n",
      "Epoch 76/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0053 - val_loss: 0.0279\n",
      "Epoch 77/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0053 - val_loss: 0.0276\n",
      "Epoch 78/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0274\n",
      "Epoch 79/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0050 - val_loss: 0.0271\n",
      "Epoch 80/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0051 - val_loss: 0.0268\n",
      "Epoch 81/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0051 - val_loss: 0.0266\n",
      "Epoch 82/82\n",
      "2080/2080 [==============================] - 3s 1ms/step - loss: 0.0049 - val_loss: 0.0264\n",
      "2081/2081 [==============================] - 1s 600us/step - loss: 0.0359\n",
      "Epoch 1/82\n",
      "2081/2081 [==============================] - 5s 2ms/step - loss: 0.3322 - val_loss: 0.0180\n",
      "Epoch 2/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.3090 - val_loss: 0.0146\n",
      "Epoch 3/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2859 - val_loss: 0.0118\n",
      "Epoch 4/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2631 - val_loss: 0.0095\n",
      "Epoch 5/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2407 - val_loss: 0.0078\n",
      "Epoch 6/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.2194 - val_loss: 0.0068\n",
      "Epoch 7/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1983 - val_loss: 0.0063\n",
      "Epoch 8/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1775 - val_loss: 0.0066\n",
      "Epoch 9/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1579 - val_loss: 0.0075\n",
      "Epoch 10/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1395 - val_loss: 0.0092\n",
      "Epoch 11/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1207 - val_loss: 0.0117\n",
      "Epoch 12/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.1045 - val_loss: 0.0148\n",
      "Epoch 13/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0890 - val_loss: 0.0186\n",
      "Epoch 14/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0231\n",
      "Epoch 15/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0620 - val_loss: 0.0280\n",
      "Epoch 16/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0508 - val_loss: 0.0335\n",
      "Epoch 17/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0420 - val_loss: 0.0392\n",
      "Epoch 18/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0341 - val_loss: 0.0450\n",
      "Epoch 19/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0281 - val_loss: 0.0506\n",
      "Epoch 20/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0234 - val_loss: 0.0561\n",
      "Epoch 21/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0194 - val_loss: 0.0609\n",
      "Epoch 22/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0172 - val_loss: 0.0653\n",
      "Epoch 23/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0146 - val_loss: 0.0692\n",
      "Epoch 24/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0136 - val_loss: 0.0725\n",
      "Epoch 25/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0125 - val_loss: 0.0751\n",
      "Epoch 26/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0118 - val_loss: 0.0772\n",
      "Epoch 27/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0113 - val_loss: 0.0789\n",
      "Epoch 28/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0112 - val_loss: 0.0803\n",
      "Epoch 29/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0108 - val_loss: 0.0815\n",
      "Epoch 30/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0110 - val_loss: 0.0821\n",
      "Epoch 31/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0108 - val_loss: 0.0827\n",
      "Epoch 32/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0104 - val_loss: 0.0830\n",
      "Epoch 33/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0107 - val_loss: 0.0832\n",
      "Epoch 34/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0103 - val_loss: 0.0832\n",
      "Epoch 35/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0831\n",
      "Epoch 36/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0830\n",
      "Epoch 37/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0100 - val_loss: 0.0827\n",
      "Epoch 38/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0102 - val_loss: 0.0826\n",
      "Epoch 39/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0100 - val_loss: 0.0823\n",
      "Epoch 40/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0099 - val_loss: 0.0820\n",
      "Epoch 41/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0103 - val_loss: 0.0817\n",
      "Epoch 42/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0099 - val_loss: 0.0814\n",
      "Epoch 43/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0096 - val_loss: 0.0810\n",
      "Epoch 44/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0099 - val_loss: 0.0806\n",
      "Epoch 45/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0098 - val_loss: 0.0804\n",
      "Epoch 46/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0097 - val_loss: 0.0801\n",
      "Epoch 47/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0099 - val_loss: 0.0797\n",
      "Epoch 48/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0098 - val_loss: 0.0793\n",
      "Epoch 49/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0097 - val_loss: 0.0789\n",
      "Epoch 50/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0094 - val_loss: 0.0785\n",
      "Epoch 51/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0096 - val_loss: 0.0781\n",
      "Epoch 52/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0095 - val_loss: 0.0777\n",
      "Epoch 53/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0095 - val_loss: 0.0774\n",
      "Epoch 54/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0095 - val_loss: 0.0772\n",
      "Epoch 55/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0094 - val_loss: 0.0767\n",
      "Epoch 56/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0097 - val_loss: 0.0763\n",
      "Epoch 57/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0095 - val_loss: 0.0759\n",
      "Epoch 58/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0090 - val_loss: 0.0756\n",
      "Epoch 59/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0753\n",
      "Epoch 60/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0092 - val_loss: 0.0748\n",
      "Epoch 61/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0093 - val_loss: 0.0745\n",
      "Epoch 62/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0091 - val_loss: 0.0741\n",
      "Epoch 63/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0090 - val_loss: 0.0737\n",
      "Epoch 64/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0088 - val_loss: 0.0733\n",
      "Epoch 65/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0090 - val_loss: 0.0728\n",
      "Epoch 66/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0088 - val_loss: 0.0724\n",
      "Epoch 67/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0088 - val_loss: 0.0722\n",
      "Epoch 68/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0089 - val_loss: 0.0718\n",
      "Epoch 69/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0089 - val_loss: 0.0713\n",
      "Epoch 70/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0085 - val_loss: 0.0711\n",
      "Epoch 71/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0087 - val_loss: 0.0707\n",
      "Epoch 72/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0087 - val_loss: 0.0703\n",
      "Epoch 73/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0087 - val_loss: 0.0698\n",
      "Epoch 74/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0088 - val_loss: 0.0695\n",
      "Epoch 75/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0086 - val_loss: 0.0691\n",
      "Epoch 76/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0083 - val_loss: 0.0689\n",
      "Epoch 77/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0084 - val_loss: 0.0685\n",
      "Epoch 78/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0084 - val_loss: 0.0682\n",
      "Epoch 79/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0085 - val_loss: 0.0677\n",
      "Epoch 80/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0086 - val_loss: 0.0675\n",
      "Epoch 81/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0083 - val_loss: 0.0670\n",
      "Epoch 82/82\n",
      "2081/2081 [==============================] - 3s 1ms/step - loss: 0.0081 - val_loss: 0.0666\n",
      "2080/2080 [==============================] - 1s 619us/step - loss: 0.0231\n",
      "Epoch 1/81\n",
      "104/104 [==============================] - 2s 6ms/step - loss: 0.0213 - val_loss: 0.0123\n",
      "Epoch 2/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0059\n",
      "Epoch 3/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9484e-04 - val_loss: 0.0042\n",
      "Epoch 4/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 7.7916e-04 - val_loss: 0.0036\n",
      "Epoch 5/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 7.5140e-04 - val_loss: 0.0030\n",
      "Epoch 6/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 7.0280e-04 - val_loss: 0.0033\n",
      "Epoch 7/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.9354e-04 - val_loss: 0.0034\n",
      "Epoch 8/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.6021e-04 - val_loss: 0.0026\n",
      "Epoch 9/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.4275e-04 - val_loss: 0.0027\n",
      "Epoch 10/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.8298e-04 - val_loss: 0.0027\n",
      "Epoch 11/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.8440e-04 - val_loss: 0.0020\n",
      "Epoch 12/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.2905e-04 - val_loss: 0.0022\n",
      "Epoch 13/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.8514e-04 - val_loss: 0.0017\n",
      "Epoch 14/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.9981e-04 - val_loss: 0.0018\n",
      "Epoch 15/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.1393e-04 - val_loss: 0.0018\n",
      "Epoch 16/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.1337e-04 - val_loss: 0.0016\n",
      "Epoch 17/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.0538e-04 - val_loss: 0.0014\n",
      "Epoch 18/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.6758e-04 - val_loss: 0.0012\n",
      "Epoch 19/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.2919e-04 - val_loss: 0.0013\n",
      "Epoch 20/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.3399e-04 - val_loss: 0.0012\n",
      "Epoch 21/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.7931e-04 - val_loss: 0.0012\n",
      "Epoch 22/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.0077e-04 - val_loss: 8.5780e-04\n",
      "Epoch 23/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.8577e-04 - val_loss: 8.6055e-04\n",
      "Epoch 24/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.9221e-04 - val_loss: 0.0010\n",
      "Epoch 25/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.4514e-04 - val_loss: 7.2894e-04\n",
      "Epoch 26/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.2935e-04 - val_loss: 7.3385e-04\n",
      "Epoch 27/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.0025e-04 - val_loss: 6.2897e-04\n",
      "Epoch 28/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.9936e-04 - val_loss: 5.8934e-04\n",
      "Epoch 29/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.9190e-04 - val_loss: 4.9673e-04\n",
      "Epoch 30/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.6940e-04 - val_loss: 6.1828e-04\n",
      "Epoch 31/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.5056e-04 - val_loss: 3.8850e-04\n",
      "Epoch 32/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.2364e-04 - val_loss: 5.3257e-04\n",
      "Epoch 33/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.3435e-04 - val_loss: 4.7262e-04\n",
      "Epoch 34/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.1566e-04 - val_loss: 3.1798e-04\n",
      "Epoch 35/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.1469e-04 - val_loss: 3.6019e-04\n",
      "Epoch 36/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.7386e-04 - val_loss: 4.5405e-04\n",
      "Epoch 37/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.7228e-04 - val_loss: 3.5375e-04\n",
      "Epoch 38/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.6553e-04 - val_loss: 3.8414e-04\n",
      "Epoch 39/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.6030e-04 - val_loss: 3.9601e-04\n",
      "Epoch 40/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.4704e-04 - val_loss: 3.8146e-04\n",
      "Epoch 41/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.5215e-04 - val_loss: 2.4593e-04\n",
      "Epoch 42/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3201e-04 - val_loss: 3.4107e-04\n",
      "Epoch 43/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3120e-04 - val_loss: 3.3816e-04\n",
      "Epoch 44/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3288e-04 - val_loss: 3.1085e-04\n",
      "Epoch 45/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.2734e-04 - val_loss: 2.3185e-04\n",
      "Epoch 46/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1629e-04 - val_loss: 2.2399e-04\n",
      "Epoch 47/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1084e-04 - val_loss: 2.6231e-04\n",
      "Epoch 48/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0276e-04 - val_loss: 1.5213e-04\n",
      "Epoch 49/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0134e-04 - val_loss: 1.7725e-04\n",
      "Epoch 50/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0167e-04 - val_loss: 2.2190e-04\n",
      "Epoch 51/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.7419e-05 - val_loss: 1.1207e-04\n",
      "Epoch 52/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.5114e-05 - val_loss: 1.4752e-04\n",
      "Epoch 53/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0152e-04 - val_loss: 3.4655e-04\n",
      "Epoch 54/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1050e-04 - val_loss: 1.4626e-04\n",
      "Epoch 55/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.2531e-05 - val_loss: 2.0332e-04\n",
      "Epoch 56/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9814e-05 - val_loss: 1.7661e-04\n",
      "Epoch 57/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.3763e-05 - val_loss: 1.2000e-04\n",
      "Epoch 58/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9025e-05 - val_loss: 2.1563e-04\n",
      "Epoch 59/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.0307e-05 - val_loss: 1.2484e-04\n",
      "Epoch 60/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.4777e-05 - val_loss: 6.1301e-05\n",
      "Epoch 61/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.6078e-05 - val_loss: 1.4258e-04\n",
      "Epoch 62/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.3468e-05 - val_loss: 5.7129e-05\n",
      "Epoch 63/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.0647e-05 - val_loss: 1.4592e-04\n",
      "Epoch 64/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.3593e-05 - val_loss: 2.0318e-04\n",
      "Epoch 65/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.5248e-05 - val_loss: 1.5462e-04\n",
      "Epoch 66/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.4278e-05 - val_loss: 2.3948e-04\n",
      "Epoch 67/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.7989e-05 - val_loss: 1.6558e-04\n",
      "Epoch 68/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.1673e-05 - val_loss: 1.2098e-04\n",
      "Epoch 69/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.4969e-05 - val_loss: 2.6127e-04\n",
      "Epoch 70/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9041e-05 - val_loss: 1.8183e-05\n",
      "Epoch 71/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.9081e-05 - val_loss: 9.9277e-05\n",
      "Epoch 72/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.8593e-05 - val_loss: 5.5607e-05\n",
      "Epoch 73/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.5729e-05 - val_loss: 9.6740e-05\n",
      "Epoch 74/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.6194e-05 - val_loss: 1.2993e-04\n",
      "Epoch 75/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.7470e-05 - val_loss: 4.5862e-05\n",
      "Epoch 76/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.2117e-05 - val_loss: 6.1471e-05\n",
      "Epoch 77/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9174e-05 - val_loss: 4.4846e-05\n",
      "Epoch 78/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.4974e-05 - val_loss: 1.2750e-04\n",
      "Epoch 79/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.1866e-05 - val_loss: 1.0125e-04\n",
      "Epoch 80/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.6717e-05 - val_loss: 5.7819e-05\n",
      "Epoch 81/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.1165e-05 - val_loss: 1.2465e-04\n",
      "105/105 [==============================] - 1s 731us/step - loss: 8.5773e-05\n",
      "Epoch 1/81\n",
      "105/105 [==============================] - 3s 6ms/step - loss: 0.0744 - val_loss: 0.0312\n",
      "Epoch 2/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0199\n",
      "Epoch 3/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0115\n",
      "Epoch 4/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 5/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0060\n",
      "Epoch 6/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 7/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 8/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 9/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 10/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 11/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 12/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 13/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 14/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 15/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 16/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 19/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.9784e-04\n",
      "Epoch 20/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 7.0178e-04\n",
      "Epoch 21/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 6.0173e-04\n",
      "Epoch 22/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 4.0301e-04\n",
      "Epoch 23/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 3.7926e-04\n",
      "Epoch 24/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 2.9685e-04\n",
      "Epoch 25/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.2613e-04\n",
      "Epoch 26/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.8999e-04\n",
      "Epoch 27/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 1.7887e-04\n",
      "Epoch 28/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.7926e-04\n",
      "Epoch 29/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 2.4253e-04\n",
      "Epoch 30/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 9.7721e-04 - val_loss: 8.8668e-05\n",
      "Epoch 31/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 1.5859e-04\n",
      "Epoch 32/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 9.7172e-04 - val_loss: 1.4460e-04\n",
      "Epoch 33/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 9.1385e-04 - val_loss: 1.5915e-04\n",
      "Epoch 34/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 8.9113e-04 - val_loss: 1.0979e-04\n",
      "Epoch 35/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 7.9637e-04 - val_loss: 6.5402e-05\n",
      "Epoch 36/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 8.2413e-04 - val_loss: 1.2827e-04\n",
      "Epoch 37/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 7.3579e-04 - val_loss: 6.4672e-05\n",
      "Epoch 38/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 7.3733e-04 - val_loss: 2.2581e-04\n",
      "Epoch 39/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.9082e-04 - val_loss: 4.9199e-05\n",
      "Epoch 40/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.5628e-04 - val_loss: 5.8233e-05\n",
      "Epoch 41/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.8165e-04 - val_loss: 8.4548e-05\n",
      "Epoch 42/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.9870e-04 - val_loss: 3.0493e-05\n",
      "Epoch 43/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.0933e-04 - val_loss: 1.4317e-04\n",
      "Epoch 44/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.1482e-04 - val_loss: 1.4534e-04\n",
      "Epoch 45/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.3268e-04 - val_loss: 4.8096e-05\n",
      "Epoch 46/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.9261e-04 - val_loss: 2.1223e-04\n",
      "Epoch 47/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.8489e-04 - val_loss: 1.0633e-04\n",
      "Epoch 48/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.7363e-04 - val_loss: 9.9972e-05\n",
      "Epoch 49/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.0677e-04 - val_loss: 1.2668e-04\n",
      "Epoch 50/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.9837e-04 - val_loss: 5.0314e-05\n",
      "Epoch 51/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.7778e-04 - val_loss: 1.6703e-05\n",
      "Epoch 52/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.8525e-04 - val_loss: 1.6228e-05\n",
      "Epoch 53/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.7940e-04 - val_loss: 9.0918e-05\n",
      "Epoch 54/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.4042e-04 - val_loss: 1.3474e-04\n",
      "Epoch 55/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.5169e-04 - val_loss: 1.8282e-05\n",
      "Epoch 56/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9593e-04 - val_loss: 1.1808e-04\n",
      "Epoch 57/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9292e-04 - val_loss: 2.0666e-05\n",
      "Epoch 58/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9858e-04 - val_loss: 2.3524e-05\n",
      "Epoch 59/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.7820e-04 - val_loss: 4.9853e-05\n",
      "Epoch 60/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9896e-04 - val_loss: 1.7296e-05\n",
      "Epoch 61/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.7477e-04 - val_loss: 3.3874e-05\n",
      "Epoch 62/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.7768e-04 - val_loss: 5.1310e-05\n",
      "Epoch 63/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.4190e-04 - val_loss: 1.5966e-05\n",
      "Epoch 64/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3340e-04 - val_loss: 2.2246e-04\n",
      "Epoch 65/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3480e-04 - val_loss: 1.0610e-04\n",
      "Epoch 66/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.7208e-04 - val_loss: 4.3863e-05\n",
      "Epoch 67/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2597e-04 - val_loss: 6.6409e-05\n",
      "Epoch 68/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3447e-04 - val_loss: 2.7636e-05\n",
      "Epoch 69/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2226e-04 - val_loss: 1.4681e-05\n",
      "Epoch 70/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1169e-04 - val_loss: 9.8618e-05\n",
      "Epoch 71/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0310e-04 - val_loss: 8.6773e-05\n",
      "Epoch 72/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0848e-04 - val_loss: 2.3646e-05\n",
      "Epoch 73/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2423e-04 - val_loss: 3.3730e-05\n",
      "Epoch 74/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0506e-04 - val_loss: 4.1843e-05\n",
      "Epoch 75/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2243e-04 - val_loss: 7.1286e-05\n",
      "Epoch 76/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0321e-04 - val_loss: 2.9091e-05\n",
      "Epoch 77/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0170e-04 - val_loss: 9.5002e-05\n",
      "Epoch 78/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8942e-04 - val_loss: 1.2829e-05\n",
      "Epoch 79/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0646e-04 - val_loss: 1.8776e-05\n",
      "Epoch 80/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0887e-04 - val_loss: 7.2835e-05\n",
      "Epoch 81/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0758e-04 - val_loss: 1.6682e-05\n",
      "104/104 [==============================] - 0s 738us/step - loss: 2.2342e-05\n",
      "Epoch 1/81\n",
      "104/104 [==============================] - 3s 6ms/step - loss: 0.1332 - val_loss: 0.0210\n",
      "Epoch 2/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.0208\n",
      "Epoch 3/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1320 - val_loss: 0.0206\n",
      "Epoch 4/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.0204\n",
      "Epoch 5/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1307 - val_loss: 0.0202\n",
      "Epoch 6/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.0200\n",
      "Epoch 7/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 0.0198\n",
      "Epoch 8/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.0196\n",
      "Epoch 9/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.0193\n",
      "Epoch 10/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.0191\n",
      "Epoch 11/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1260 - val_loss: 0.0189\n",
      "Epoch 12/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.0186\n",
      "Epoch 13/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.0184\n",
      "Epoch 14/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.0181\n",
      "Epoch 15/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.0179\n",
      "Epoch 16/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1215 - val_loss: 0.0176\n",
      "Epoch 17/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1207 - val_loss: 0.0174\n",
      "Epoch 18/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.0171\n",
      "Epoch 19/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.0169\n",
      "Epoch 20/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.0166\n",
      "Epoch 21/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.0164\n",
      "Epoch 22/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.0161\n",
      "Epoch 23/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1148 - val_loss: 0.0158\n",
      "Epoch 24/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.0156\n",
      "Epoch 25/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1129 - val_loss: 0.0153\n",
      "Epoch 26/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1119 - val_loss: 0.0151\n",
      "Epoch 27/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.0148\n",
      "Epoch 28/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.0146\n",
      "Epoch 29/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1088 - val_loss: 0.0143\n",
      "Epoch 30/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.0141\n",
      "Epoch 31/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.0138\n",
      "Epoch 32/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.0136\n",
      "Epoch 33/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.0133\n",
      "Epoch 34/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.0131\n",
      "Epoch 35/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.0129\n",
      "Epoch 36/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.0126\n",
      "Epoch 37/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.0124\n",
      "Epoch 38/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.0122\n",
      "Epoch 39/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.0119\n",
      "Epoch 40/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.0117\n",
      "Epoch 41/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0115\n",
      "Epoch 42/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.0113\n",
      "Epoch 43/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 0.0111\n",
      "Epoch 44/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 0.0109\n",
      "Epoch 45/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0106\n",
      "Epoch 46/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.0104\n",
      "Epoch 47/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0102\n",
      "Epoch 48/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0101\n",
      "Epoch 49/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0099\n",
      "Epoch 50/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 0.0097\n",
      "Epoch 51/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0095\n",
      "Epoch 52/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0093\n",
      "Epoch 53/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0092\n",
      "Epoch 54/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0090\n",
      "Epoch 55/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0088\n",
      "Epoch 56/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0087\n",
      "Epoch 57/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0085\n",
      "Epoch 58/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0084\n",
      "Epoch 59/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0083\n",
      "Epoch 60/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0081\n",
      "Epoch 61/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0080\n",
      "Epoch 62/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0079\n",
      "Epoch 63/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0734 - val_loss: 0.0078\n",
      "Epoch 64/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0077\n",
      "Epoch 65/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0076\n",
      "Epoch 66/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0075\n",
      "Epoch 67/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0074\n",
      "Epoch 68/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0073\n",
      "Epoch 69/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0072\n",
      "Epoch 70/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0071\n",
      "Epoch 71/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0071\n",
      "Epoch 72/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0648 - val_loss: 0.0070\n",
      "Epoch 73/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0070\n",
      "Epoch 74/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0069\n",
      "Epoch 75/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0069\n",
      "Epoch 76/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0068\n",
      "Epoch 77/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0068\n",
      "Epoch 78/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.0068\n",
      "Epoch 79/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0068\n",
      "Epoch 80/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0068\n",
      "Epoch 81/81\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0068\n",
      "105/105 [==============================] - 1s 741us/step - loss: 0.1957\n",
      "Epoch 1/81\n",
      "105/105 [==============================] - 3s 6ms/step - loss: 0.3440 - val_loss: 0.0211\n",
      "Epoch 2/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.0209\n",
      "Epoch 3/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3416 - val_loss: 0.0207\n",
      "Epoch 4/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.0205\n",
      "Epoch 5/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.0203\n",
      "Epoch 6/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.0200\n",
      "Epoch 7/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.0198\n",
      "Epoch 8/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.0196\n",
      "Epoch 9/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3321 - val_loss: 0.0193\n",
      "Epoch 10/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.0191\n",
      "Epoch 11/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.0188\n",
      "Epoch 12/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3268 - val_loss: 0.0185\n",
      "Epoch 13/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3247 - val_loss: 0.0183\n",
      "Epoch 14/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.0180\n",
      "Epoch 15/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.0177\n",
      "Epoch 16/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3189 - val_loss: 0.0175\n",
      "Epoch 17/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.0172\n",
      "Epoch 18/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.0169\n",
      "Epoch 19/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3130 - val_loss: 0.0166\n",
      "Epoch 20/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3107 - val_loss: 0.0164\n",
      "Epoch 21/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3086 - val_loss: 0.0161\n",
      "Epoch 22/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.0158\n",
      "Epoch 23/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.0155\n",
      "Epoch 24/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3020 - val_loss: 0.0152\n",
      "Epoch 25/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.0149\n",
      "Epoch 26/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2979 - val_loss: 0.0147\n",
      "Epoch 27/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.0144\n",
      "Epoch 28/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2934 - val_loss: 0.0141\n",
      "Epoch 29/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2909 - val_loss: 0.0138\n",
      "Epoch 30/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2885 - val_loss: 0.0136\n",
      "Epoch 31/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2865 - val_loss: 0.0133\n",
      "Epoch 32/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2840 - val_loss: 0.0130\n",
      "Epoch 33/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 0.0127\n",
      "Epoch 34/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.0125\n",
      "Epoch 35/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2768 - val_loss: 0.0122\n",
      "Epoch 36/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2747 - val_loss: 0.0119\n",
      "Epoch 37/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2720 - val_loss: 0.0117\n",
      "Epoch 38/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2698 - val_loss: 0.0114\n",
      "Epoch 39/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2672 - val_loss: 0.0112\n",
      "Epoch 40/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2650 - val_loss: 0.0109\n",
      "Epoch 41/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2624 - val_loss: 0.0107\n",
      "Epoch 42/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2601 - val_loss: 0.0104\n",
      "Epoch 43/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2575 - val_loss: 0.0102\n",
      "Epoch 44/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2550 - val_loss: 0.0100\n",
      "Epoch 45/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2525 - val_loss: 0.0097\n",
      "Epoch 46/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2500 - val_loss: 0.0095\n",
      "Epoch 47/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2475 - val_loss: 0.0093\n",
      "Epoch 48/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2448 - val_loss: 0.0091\n",
      "Epoch 49/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2426 - val_loss: 0.0089\n",
      "Epoch 50/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2396 - val_loss: 0.0087\n",
      "Epoch 51/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2372 - val_loss: 0.0085\n",
      "Epoch 52/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2347 - val_loss: 0.0083\n",
      "Epoch 53/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2318 - val_loss: 0.0081\n",
      "Epoch 54/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2295 - val_loss: 0.0079\n",
      "Epoch 55/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2266 - val_loss: 0.0077\n",
      "Epoch 56/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2244 - val_loss: 0.0075\n",
      "Epoch 57/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2210 - val_loss: 0.0074\n",
      "Epoch 58/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2187 - val_loss: 0.0072\n",
      "Epoch 59/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2159 - val_loss: 0.0071\n",
      "Epoch 60/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2130 - val_loss: 0.0069\n",
      "Epoch 61/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2105 - val_loss: 0.0068\n",
      "Epoch 62/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2080 - val_loss: 0.0067\n",
      "Epoch 63/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2050 - val_loss: 0.0066\n",
      "Epoch 64/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2023 - val_loss: 0.0065\n",
      "Epoch 65/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1998 - val_loss: 0.0064\n",
      "Epoch 66/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.0063\n",
      "Epoch 67/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.0062\n",
      "Epoch 68/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1914 - val_loss: 0.0061\n",
      "Epoch 69/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1882 - val_loss: 0.0061\n",
      "Epoch 70/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.0060\n",
      "Epoch 71/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1830 - val_loss: 0.0060\n",
      "Epoch 72/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1801 - val_loss: 0.0060\n",
      "Epoch 73/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1774 - val_loss: 0.0059\n",
      "Epoch 74/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1754 - val_loss: 0.0059\n",
      "Epoch 75/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1720 - val_loss: 0.0059\n",
      "Epoch 76/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1693 - val_loss: 0.0060\n",
      "Epoch 77/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1670 - val_loss: 0.0060\n",
      "Epoch 78/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.0060\n",
      "Epoch 79/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1614 - val_loss: 0.0061\n",
      "Epoch 80/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.0062\n",
      "Epoch 81/81\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.0062\n",
      "104/104 [==============================] - 0s 748us/step - loss: 0.0394\n",
      "Epoch 1/82\n",
      "104/104 [==============================] - 2s 6ms/step - loss: 0.0268 - val_loss: 0.0147\n",
      "Epoch 2/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0074\n",
      "Epoch 3/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.4372e-04 - val_loss: 0.0047\n",
      "Epoch 4/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.1455e-04 - val_loss: 0.0045\n",
      "Epoch 5/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.3012e-04 - val_loss: 0.0042\n",
      "Epoch 6/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 7.4942e-04 - val_loss: 0.0036\n",
      "Epoch 7/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.8376e-04 - val_loss: 0.0035\n",
      "Epoch 8/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.7762e-04 - val_loss: 0.0031\n",
      "Epoch 9/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.4712e-04 - val_loss: 0.0030\n",
      "Epoch 10/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.4438e-04 - val_loss: 0.0031\n",
      "Epoch 11/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 6.8996e-04 - val_loss: 0.0028\n",
      "Epoch 12/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.9530e-04 - val_loss: 0.0031\n",
      "Epoch 13/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.9620e-04 - val_loss: 0.0026\n",
      "Epoch 14/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.3158e-04 - val_loss: 0.0022\n",
      "Epoch 15/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.7479e-04 - val_loss: 0.0021\n",
      "Epoch 16/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.4118e-04 - val_loss: 0.0021\n",
      "Epoch 17/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 5.4479e-04 - val_loss: 0.0016\n",
      "Epoch 18/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.7013e-04 - val_loss: 0.0015\n",
      "Epoch 19/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.7274e-04 - val_loss: 0.0016\n",
      "Epoch 20/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.3273e-04 - val_loss: 0.0011\n",
      "Epoch 21/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.5071e-04 - val_loss: 0.0012\n",
      "Epoch 22/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 4.3105e-04 - val_loss: 9.7573e-04\n",
      "Epoch 23/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.9271e-04 - val_loss: 0.0013\n",
      "Epoch 24/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.9124e-04 - val_loss: 8.0853e-04\n",
      "Epoch 25/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.4998e-04 - val_loss: 8.6744e-04\n",
      "Epoch 26/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.7195e-04 - val_loss: 7.3255e-04\n",
      "Epoch 27/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.4764e-04 - val_loss: 7.4501e-04\n",
      "Epoch 28/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.9693e-04 - val_loss: 5.1992e-04\n",
      "Epoch 29/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.0414e-04 - val_loss: 6.9365e-04\n",
      "Epoch 30/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 3.0257e-04 - val_loss: 7.2011e-04\n",
      "Epoch 31/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.7234e-04 - val_loss: 6.2001e-04\n",
      "Epoch 32/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.3192e-04 - val_loss: 4.6055e-04\n",
      "Epoch 33/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.6791e-04 - val_loss: 4.1837e-04\n",
      "Epoch 34/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.4535e-04 - val_loss: 3.4769e-04\n",
      "Epoch 35/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.1857e-04 - val_loss: 4.5541e-04\n",
      "Epoch 36/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 2.1021e-04 - val_loss: 3.5768e-04\n",
      "Epoch 37/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.8974e-04 - val_loss: 4.4409e-04\n",
      "Epoch 38/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.8188e-04 - val_loss: 2.7971e-04\n",
      "Epoch 39/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.7554e-04 - val_loss: 3.2076e-04\n",
      "Epoch 40/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.5403e-04 - val_loss: 2.3913e-04\n",
      "Epoch 41/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.6062e-04 - val_loss: 2.4258e-04\n",
      "Epoch 42/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.4908e-04 - val_loss: 2.0387e-04\n",
      "Epoch 43/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3259e-04 - val_loss: 2.5827e-04\n",
      "Epoch 44/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3469e-04 - val_loss: 4.2719e-04\n",
      "Epoch 45/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.3316e-04 - val_loss: 3.2524e-04\n",
      "Epoch 46/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.2173e-04 - val_loss: 3.3922e-04\n",
      "Epoch 47/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1537e-04 - val_loss: 2.6639e-04\n",
      "Epoch 48/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1543e-04 - val_loss: 1.8241e-04\n",
      "Epoch 49/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0505e-04 - val_loss: 1.9885e-04\n",
      "Epoch 50/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1484e-04 - val_loss: 1.1393e-04\n",
      "Epoch 51/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.1407e-04 - val_loss: 1.3111e-04\n",
      "Epoch 52/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0443e-04 - val_loss: 8.2986e-05\n",
      "Epoch 53/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0320e-04 - val_loss: 1.8004e-04\n",
      "Epoch 54/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.6996e-05 - val_loss: 1.0916e-04\n",
      "Epoch 55/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9189e-05 - val_loss: 9.0046e-05\n",
      "Epoch 56/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.3075e-05 - val_loss: 1.0067e-04\n",
      "Epoch 57/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.7056e-05 - val_loss: 9.6213e-05\n",
      "Epoch 58/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.1917e-05 - val_loss: 8.5892e-05\n",
      "Epoch 59/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.1546e-05 - val_loss: 8.7332e-05\n",
      "Epoch 60/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.1571e-05 - val_loss: 6.4933e-05\n",
      "Epoch 61/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0261e-04 - val_loss: 2.5612e-05\n",
      "Epoch 62/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.5500e-05 - val_loss: 9.9614e-05\n",
      "Epoch 63/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0008e-04 - val_loss: 1.1329e-04\n",
      "Epoch 64/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.0588e-05 - val_loss: 1.2160e-04\n",
      "Epoch 65/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.5355e-05 - val_loss: 5.9308e-05\n",
      "Epoch 66/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9362e-05 - val_loss: 9.8850e-05\n",
      "Epoch 67/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.3636e-05 - val_loss: 3.0244e-05\n",
      "Epoch 68/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.9146e-05 - val_loss: 5.6274e-05\n",
      "Epoch 69/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.4493e-05 - val_loss: 2.7785e-05\n",
      "Epoch 70/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.8438e-05 - val_loss: 1.6785e-04\n",
      "Epoch 71/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9772e-05 - val_loss: 2.2060e-05\n",
      "Epoch 72/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.7812e-05 - val_loss: 7.6411e-05\n",
      "Epoch 73/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.6433e-05 - val_loss: 7.9004e-05\n",
      "Epoch 74/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 1.0070e-04 - val_loss: 1.1901e-04\n",
      "Epoch 75/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.5049e-05 - val_loss: 5.5975e-05\n",
      "Epoch 76/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.2125e-05 - val_loss: 1.0015e-04\n",
      "Epoch 77/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.5664e-05 - val_loss: 1.4607e-04\n",
      "Epoch 78/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.9264e-05 - val_loss: 9.5968e-05\n",
      "Epoch 79/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.8624e-05 - val_loss: 6.8086e-05\n",
      "Epoch 80/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.9782e-05 - val_loss: 3.7578e-05\n",
      "Epoch 81/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 8.7451e-05 - val_loss: 7.8642e-05\n",
      "Epoch 82/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 9.4992e-05 - val_loss: 7.7353e-05\n",
      "105/105 [==============================] - 1s 760us/step - loss: 6.8478e-05\n",
      "Epoch 1/82\n",
      "105/105 [==============================] - 3s 6ms/step - loss: 0.0730 - val_loss: 0.0332\n",
      "Epoch 2/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0207\n",
      "Epoch 3/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0117\n",
      "Epoch 4/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0085\n",
      "Epoch 5/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0079\n",
      "Epoch 6/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0080\n",
      "Epoch 7/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 8/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 9/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 10/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 11/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 12/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 13/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0026\n",
      "Epoch 14/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 15/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 16/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 17/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 18/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 9.0779e-04\n",
      "Epoch 19/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 8.2767e-04\n",
      "Epoch 20/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 7.7530e-04\n",
      "Epoch 21/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 5.2146e-04\n",
      "Epoch 22/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 8.2362e-04\n",
      "Epoch 23/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 5.3637e-04\n",
      "Epoch 24/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.0386e-04\n",
      "Epoch 25/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 2.9652e-04\n",
      "Epoch 26/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.8528e-04\n",
      "Epoch 27/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 4.2239e-04\n",
      "Epoch 28/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 3.6632e-04\n",
      "Epoch 29/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 9.8521e-04 - val_loss: 3.2023e-04\n",
      "Epoch 30/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.5983e-04\n",
      "Epoch 31/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 6.5599e-05\n",
      "Epoch 32/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 1.7863e-04\n",
      "Epoch 33/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 8.7634e-04 - val_loss: 3.8377e-04\n",
      "Epoch 34/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 8.7850e-04 - val_loss: 1.2544e-04\n",
      "Epoch 35/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 8.2786e-04 - val_loss: 1.0591e-04\n",
      "Epoch 36/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 8.1742e-04 - val_loss: 2.1260e-04\n",
      "Epoch 37/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 7.6737e-04 - val_loss: 1.4632e-04\n",
      "Epoch 38/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.8209e-04 - val_loss: 1.4231e-04\n",
      "Epoch 39/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.3034e-04 - val_loss: 1.1352e-04\n",
      "Epoch 40/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.7308e-04 - val_loss: 1.3175e-04\n",
      "Epoch 41/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.6255e-04 - val_loss: 6.4530e-05\n",
      "Epoch 42/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.7731e-04 - val_loss: 3.4487e-05\n",
      "Epoch 43/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 6.1082e-04 - val_loss: 5.1756e-05\n",
      "Epoch 44/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.5358e-04 - val_loss: 3.0568e-04\n",
      "Epoch 45/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.1903e-04 - val_loss: 1.8846e-04\n",
      "Epoch 46/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.0440e-04 - val_loss: 4.9543e-05\n",
      "Epoch 47/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 5.0346e-04 - val_loss: 2.2772e-04\n",
      "Epoch 48/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.3506e-04 - val_loss: 1.8213e-04\n",
      "Epoch 49/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.8645e-04 - val_loss: 4.2741e-05\n",
      "Epoch 50/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.2511e-04 - val_loss: 5.0965e-05\n",
      "Epoch 51/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 4.1151e-04 - val_loss: 6.0285e-05\n",
      "Epoch 52/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.5914e-04 - val_loss: 9.3493e-05\n",
      "Epoch 53/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.6367e-04 - val_loss: 2.7858e-05\n",
      "Epoch 54/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.3534e-04 - val_loss: 1.0636e-04\n",
      "Epoch 55/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.4413e-04 - val_loss: 1.0596e-04\n",
      "Epoch 56/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.1471e-04 - val_loss: 1.0228e-04\n",
      "Epoch 57/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.1650e-04 - val_loss: 1.8611e-04\n",
      "Epoch 58/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.8479e-04 - val_loss: 1.1599e-04\n",
      "Epoch 59/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9961e-04 - val_loss: 3.3878e-05\n",
      "Epoch 60/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.0248e-04 - val_loss: 2.1822e-04\n",
      "Epoch 61/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.8420e-04 - val_loss: 5.5802e-05\n",
      "Epoch 62/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 3.1327e-04 - val_loss: 2.2025e-05\n",
      "Epoch 63/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.9306e-04 - val_loss: 3.8181e-05\n",
      "Epoch 64/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2069e-04 - val_loss: 1.0023e-04\n",
      "Epoch 65/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.5541e-04 - val_loss: 2.4871e-05\n",
      "Epoch 66/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2902e-04 - val_loss: 3.7719e-05\n",
      "Epoch 67/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2215e-04 - val_loss: 2.8004e-05\n",
      "Epoch 68/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2361e-04 - val_loss: 8.9565e-05\n",
      "Epoch 69/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2945e-04 - val_loss: 1.7082e-04\n",
      "Epoch 70/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3010e-04 - val_loss: 3.0983e-04\n",
      "Epoch 71/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.2432e-04 - val_loss: 1.1003e-04\n",
      "Epoch 72/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1340e-04 - val_loss: 1.0372e-04\n",
      "Epoch 73/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1259e-04 - val_loss: 8.7707e-05\n",
      "Epoch 74/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0685e-04 - val_loss: 1.9857e-04\n",
      "Epoch 75/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1340e-04 - val_loss: 6.0566e-05\n",
      "Epoch 76/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0064e-04 - val_loss: 4.6936e-05\n",
      "Epoch 77/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.9323e-04 - val_loss: 2.6094e-04\n",
      "Epoch 78/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.1816e-04 - val_loss: 1.8738e-05\n",
      "Epoch 79/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.3660e-04 - val_loss: 1.8865e-05\n",
      "Epoch 80/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.8636e-04 - val_loss: 1.1957e-04\n",
      "Epoch 81/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 2.0374e-04 - val_loss: 2.4310e-05\n",
      "Epoch 82/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.9566e-04 - val_loss: 1.5806e-05\n",
      "104/104 [==============================] - 0s 689us/step - loss: 5.0269e-05\n",
      "Epoch 1/82\n",
      "104/104 [==============================] - 2s 6ms/step - loss: 0.1311 - val_loss: 0.0206\n",
      "Epoch 2/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.0204\n",
      "Epoch 3/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.0202\n",
      "Epoch 4/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1290 - val_loss: 0.0200\n",
      "Epoch 5/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1282 - val_loss: 0.0198\n",
      "Epoch 6/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.0195\n",
      "Epoch 7/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.0193\n",
      "Epoch 8/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 0.0191\n",
      "Epoch 9/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1249 - val_loss: 0.0188\n",
      "Epoch 10/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.0186\n",
      "Epoch 11/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.0183\n",
      "Epoch 12/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.0181\n",
      "Epoch 13/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.0178\n",
      "Epoch 14/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.0176\n",
      "Epoch 15/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.0173\n",
      "Epoch 16/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.0170\n",
      "Epoch 17/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.0168\n",
      "Epoch 18/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.0165\n",
      "Epoch 19/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.0162\n",
      "Epoch 20/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1142 - val_loss: 0.0160\n",
      "Epoch 21/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1131 - val_loss: 0.0157\n",
      "Epoch 22/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1120 - val_loss: 0.0154\n",
      "Epoch 23/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.0152\n",
      "Epoch 24/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.0149\n",
      "Epoch 25/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1091 - val_loss: 0.0146\n",
      "Epoch 26/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1078 - val_loss: 0.0144\n",
      "Epoch 27/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.0141\n",
      "Epoch 28/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1057 - val_loss: 0.0139\n",
      "Epoch 29/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1048 - val_loss: 0.0136\n",
      "Epoch 30/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1036 - val_loss: 0.0133\n",
      "Epoch 31/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.0131\n",
      "Epoch 32/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1015 - val_loss: 0.0128\n",
      "Epoch 33/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.0126\n",
      "Epoch 34/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 0.0124\n",
      "Epoch 35/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.0121\n",
      "Epoch 36/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 0.0119\n",
      "Epoch 37/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.0116\n",
      "Epoch 38/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0948 - val_loss: 0.0114\n",
      "Epoch 39/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0112\n",
      "Epoch 40/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0110\n",
      "Epoch 41/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.0107\n",
      "Epoch 42/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0105\n",
      "Epoch 43/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0103\n",
      "Epoch 44/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0101\n",
      "Epoch 45/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0099\n",
      "Epoch 46/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0097\n",
      "Epoch 47/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0095\n",
      "Epoch 48/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 0.0093\n",
      "Epoch 49/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0091\n",
      "Epoch 50/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0089\n",
      "Epoch 51/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0088\n",
      "Epoch 52/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0086\n",
      "Epoch 53/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0084\n",
      "Epoch 54/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0083\n",
      "Epoch 55/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0081\n",
      "Epoch 56/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0080\n",
      "Epoch 57/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0078\n",
      "Epoch 58/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.0077\n",
      "Epoch 59/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0076\n",
      "Epoch 60/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0075\n",
      "Epoch 61/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0074\n",
      "Epoch 62/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0072\n",
      "Epoch 63/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0071\n",
      "Epoch 64/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0070\n",
      "Epoch 65/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0069\n",
      "Epoch 66/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0069\n",
      "Epoch 67/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0068\n",
      "Epoch 68/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.0067\n",
      "Epoch 69/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0067\n",
      "Epoch 70/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0066\n",
      "Epoch 71/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.0065\n",
      "Epoch 72/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.0065\n",
      "Epoch 73/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0065\n",
      "Epoch 74/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0064\n",
      "Epoch 75/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0064\n",
      "Epoch 76/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0064\n",
      "Epoch 77/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0064\n",
      "Epoch 78/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0064\n",
      "Epoch 79/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0064\n",
      "Epoch 80/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0064\n",
      "Epoch 81/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0064\n",
      "Epoch 82/82\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.0499 - val_loss: 0.0064\n",
      "105/105 [==============================] - 1s 750us/step - loss: 0.1793\n",
      "Epoch 1/82\n",
      "105/105 [==============================] - 3s 6ms/step - loss: 0.3465 - val_loss: 0.0214\n",
      "Epoch 2/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.0212\n",
      "Epoch 3/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.0210\n",
      "Epoch 4/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.0207\n",
      "Epoch 5/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.0205\n",
      "Epoch 6/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3394 - val_loss: 0.0203\n",
      "Epoch 7/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.0200\n",
      "Epoch 8/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3361 - val_loss: 0.0198\n",
      "Epoch 9/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.0195\n",
      "Epoch 10/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3326 - val_loss: 0.0192\n",
      "Epoch 11/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.0190\n",
      "Epoch 12/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.0187\n",
      "Epoch 13/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3270 - val_loss: 0.0184\n",
      "Epoch 14/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 0.0181\n",
      "Epoch 15/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.0178\n",
      "Epoch 16/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3211 - val_loss: 0.0176\n",
      "Epoch 17/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3193 - val_loss: 0.0173\n",
      "Epoch 18/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.0170\n",
      "Epoch 19/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3150 - val_loss: 0.0167\n",
      "Epoch 20/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 0.0164\n",
      "Epoch 21/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3107 - val_loss: 0.0161\n",
      "Epoch 22/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3085 - val_loss: 0.0158\n",
      "Epoch 23/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3063 - val_loss: 0.0155\n",
      "Epoch 24/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.0152\n",
      "Epoch 25/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.0149\n",
      "Epoch 26/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.0146\n",
      "Epoch 27/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2975 - val_loss: 0.0143\n",
      "Epoch 28/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2950 - val_loss: 0.0140\n",
      "Epoch 29/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2928 - val_loss: 0.0138\n",
      "Epoch 30/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2904 - val_loss: 0.0135\n",
      "Epoch 31/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2879 - val_loss: 0.0132\n",
      "Epoch 32/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2855 - val_loss: 0.0129\n",
      "Epoch 33/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.0126\n",
      "Epoch 34/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2809 - val_loss: 0.0123\n",
      "Epoch 35/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2785 - val_loss: 0.0121\n",
      "Epoch 36/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2760 - val_loss: 0.0118\n",
      "Epoch 37/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2734 - val_loss: 0.0115\n",
      "Epoch 38/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2712 - val_loss: 0.0113\n",
      "Epoch 39/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2687 - val_loss: 0.0110\n",
      "Epoch 40/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2661 - val_loss: 0.0108\n",
      "Epoch 41/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2634 - val_loss: 0.0105\n",
      "Epoch 42/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2614 - val_loss: 0.0103\n",
      "Epoch 43/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2585 - val_loss: 0.0100\n",
      "Epoch 44/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2560 - val_loss: 0.0098\n",
      "Epoch 45/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.0095\n",
      "Epoch 46/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2510 - val_loss: 0.0093\n",
      "Epoch 47/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2482 - val_loss: 0.0091\n",
      "Epoch 48/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2459 - val_loss: 0.0089\n",
      "Epoch 49/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2427 - val_loss: 0.0087\n",
      "Epoch 50/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2402 - val_loss: 0.0085\n",
      "Epoch 51/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2374 - val_loss: 0.0083\n",
      "Epoch 52/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2349 - val_loss: 0.0081\n",
      "Epoch 53/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2325 - val_loss: 0.0079\n",
      "Epoch 54/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2294 - val_loss: 0.0078\n",
      "Epoch 55/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2269 - val_loss: 0.0076\n",
      "Epoch 56/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2242 - val_loss: 0.0074\n",
      "Epoch 57/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2213 - val_loss: 0.0073\n",
      "Epoch 58/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2186 - val_loss: 0.0071\n",
      "Epoch 59/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2162 - val_loss: 0.0070\n",
      "Epoch 60/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2131 - val_loss: 0.0069\n",
      "Epoch 61/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2100 - val_loss: 0.0068\n",
      "Epoch 62/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2079 - val_loss: 0.0067\n",
      "Epoch 63/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2050 - val_loss: 0.0066\n",
      "Epoch 64/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.2025 - val_loss: 0.0065\n",
      "Epoch 65/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1993 - val_loss: 0.0064\n",
      "Epoch 66/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1962 - val_loss: 0.0064\n",
      "Epoch 67/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.0063\n",
      "Epoch 68/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1910 - val_loss: 0.0063\n",
      "Epoch 69/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1887 - val_loss: 0.0063\n",
      "Epoch 70/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.0063\n",
      "Epoch 71/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.0063\n",
      "Epoch 72/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1796 - val_loss: 0.0063\n",
      "Epoch 73/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1770 - val_loss: 0.0063\n",
      "Epoch 74/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1743 - val_loss: 0.0063\n",
      "Epoch 75/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1715 - val_loss: 0.0064\n",
      "Epoch 76/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1687 - val_loss: 0.0065\n",
      "Epoch 77/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1653 - val_loss: 0.0065\n",
      "Epoch 78/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.0066\n",
      "Epoch 79/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.0067\n",
      "Epoch 80/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.0069\n",
      "Epoch 81/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.0070\n",
      "Epoch 82/82\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.0072\n",
      "104/104 [==============================] - 0s 728us/step - loss: 0.0368\n",
      "Epoch 1/81\n",
      "209/209 [==============================] - 3s 4ms/step - loss: 0.0282 - val_loss: 0.0064\n",
      "Epoch 2/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 3/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 4/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 5/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 9.3205e-04\n",
      "Epoch 6/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 5.3739e-04\n",
      "Epoch 7/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 4.5772e-04\n",
      "Epoch 8/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 2.9022e-04\n",
      "Epoch 9/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 9.1833e-04 - val_loss: 2.7002e-04\n",
      "Epoch 10/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 9.4654e-04 - val_loss: 2.2869e-04\n",
      "Epoch 11/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 8.5293e-04 - val_loss: 2.8987e-04\n",
      "Epoch 12/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 8.2960e-04 - val_loss: 1.6855e-04\n",
      "Epoch 13/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 7.5443e-04 - val_loss: 1.6533e-04\n",
      "Epoch 14/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 7.1242e-04 - val_loss: 1.6769e-04\n",
      "Epoch 15/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 6.5910e-04 - val_loss: 9.3802e-05\n",
      "Epoch 16/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 6.3432e-04 - val_loss: 2.6687e-04\n",
      "Epoch 17/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 5.6792e-04 - val_loss: 5.6476e-05\n",
      "Epoch 18/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 4.9514e-04 - val_loss: 7.3340e-05\n",
      "Epoch 19/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 4.6879e-04 - val_loss: 1.6080e-04\n",
      "Epoch 20/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 4.2752e-04 - val_loss: 6.9745e-05\n",
      "Epoch 21/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 3.9980e-04 - val_loss: 4.1689e-05\n",
      "Epoch 22/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 3.9080e-04 - val_loss: 5.0902e-05\n",
      "Epoch 23/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 3.3425e-04 - val_loss: 3.2565e-05\n",
      "Epoch 24/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 3.2118e-04 - val_loss: 2.8682e-05\n",
      "Epoch 25/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 3.0286e-04 - val_loss: 3.1986e-05\n",
      "Epoch 26/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.6841e-04 - val_loss: 4.8894e-05\n",
      "Epoch 27/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.7998e-04 - val_loss: 1.6731e-04\n",
      "Epoch 28/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.4600e-04 - val_loss: 6.5193e-05\n",
      "Epoch 29/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.5139e-04 - val_loss: 1.4871e-04\n",
      "Epoch 30/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2695e-04 - val_loss: 2.0678e-05\n",
      "Epoch 31/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2474e-04 - val_loss: 6.1923e-05\n",
      "Epoch 32/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.3894e-04 - val_loss: 1.4742e-04\n",
      "Epoch 33/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2056e-04 - val_loss: 3.9033e-05\n",
      "Epoch 34/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1971e-04 - val_loss: 1.9208e-04\n",
      "Epoch 35/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1008e-04 - val_loss: 4.8117e-05\n",
      "Epoch 36/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0145e-04 - val_loss: 1.9741e-05\n",
      "Epoch 37/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0163e-04 - val_loss: 2.1052e-05\n",
      "Epoch 38/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0293e-04 - val_loss: 2.5570e-05\n",
      "Epoch 39/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1153e-04 - val_loss: 7.2626e-05\n",
      "Epoch 40/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0427e-04 - val_loss: 6.7773e-05\n",
      "Epoch 41/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.6024e-04 - val_loss: 4.8530e-05\n",
      "Epoch 42/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9411e-04 - val_loss: 3.6602e-05\n",
      "Epoch 43/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2060e-04 - val_loss: 3.2528e-05\n",
      "Epoch 44/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9958e-04 - val_loss: 2.4382e-04\n",
      "Epoch 45/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1307e-04 - val_loss: 2.3755e-04\n",
      "Epoch 46/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0735e-04 - val_loss: 1.3760e-04\n",
      "Epoch 47/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1070e-04 - val_loss: 1.6620e-04\n",
      "Epoch 48/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1200e-04 - val_loss: 3.6152e-05\n",
      "Epoch 49/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0481e-04 - val_loss: 5.9270e-05\n",
      "Epoch 50/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2723e-04 - val_loss: 3.7072e-04\n",
      "Epoch 51/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0977e-04 - val_loss: 6.4832e-05\n",
      "Epoch 52/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0358e-04 - val_loss: 8.7543e-05\n",
      "Epoch 53/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0632e-04 - val_loss: 5.7430e-05\n",
      "Epoch 54/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0578e-04 - val_loss: 7.4074e-05\n",
      "Epoch 55/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0322e-04 - val_loss: 9.9084e-05\n",
      "Epoch 56/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9887e-04 - val_loss: 1.5823e-04\n",
      "Epoch 57/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0466e-04 - val_loss: 1.2034e-05\n",
      "Epoch 58/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0737e-04 - val_loss: 2.7319e-04\n",
      "Epoch 59/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1245e-04 - val_loss: 3.5874e-04\n",
      "Epoch 60/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1961e-04 - val_loss: 3.7047e-04\n",
      "Epoch 61/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9251e-04 - val_loss: 1.1448e-04\n",
      "Epoch 62/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1897e-04 - val_loss: 3.5934e-05\n",
      "Epoch 63/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9816e-04 - val_loss: 1.0511e-04\n",
      "Epoch 64/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9238e-04 - val_loss: 6.7539e-05\n",
      "Epoch 65/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0733e-04 - val_loss: 3.9811e-05\n",
      "Epoch 66/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0227e-04 - val_loss: 1.1772e-05\n",
      "Epoch 67/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9614e-04 - val_loss: 1.3861e-04\n",
      "Epoch 68/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9739e-04 - val_loss: 5.6223e-05\n",
      "Epoch 69/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2049e-04 - val_loss: 1.6313e-04\n",
      "Epoch 70/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.2180e-04 - val_loss: 6.0364e-05\n",
      "Epoch 71/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0114e-04 - val_loss: 1.8766e-04\n",
      "Epoch 72/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9457e-04 - val_loss: 2.0615e-04\n",
      "Epoch 73/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0477e-04 - val_loss: 1.6889e-04\n",
      "Epoch 74/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9844e-04 - val_loss: 1.0180e-04\n",
      "Epoch 75/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.1965e-04 - val_loss: 1.1367e-04\n",
      "Epoch 76/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9760e-04 - val_loss: 8.4918e-05\n",
      "Epoch 77/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9601e-04 - val_loss: 3.1998e-05\n",
      "Epoch 78/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0418e-04 - val_loss: 5.7783e-05\n",
      "Epoch 79/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9433e-04 - val_loss: 1.8619e-05\n",
      "Epoch 80/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 2.0526e-04 - val_loss: 2.2722e-05\n",
      "Epoch 81/81\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.9561e-04 - val_loss: 1.1096e-04\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9e26e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 20, 'epochs': 81, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6851ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model=grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f0b2e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2d2f64100a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eeb97d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 781us/step\n"
     ]
    }
   ],
   "source": [
    "prediction=my_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8699c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      " [[0.39728257]\n",
      " [0.39896664]\n",
      " [0.39498776]\n",
      " ...\n",
      " [0.15229398]\n",
      " [0.15754312]\n",
      " [0.1585716 ]]\n",
      "\n",
      "Prediction Shape- (1040, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction\\n\", prediction)\n",
    "print(\"\\nPrediction Shape-\",prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2be6090a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8c654a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44862c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies_array = np.repeat(prediction,5, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1dbd500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_copies_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b00bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39728257, 0.39728257, 0.39728257, 0.39728257, 0.39728257],\n",
       "       [0.39896664, 0.39896664, 0.39896664, 0.39896664, 0.39896664],\n",
       "       [0.39498776, 0.39498776, 0.39498776, 0.39498776, 0.39498776],\n",
       "       ...,\n",
       "       [0.15229398, 0.15229398, 0.15229398, 0.15229398, 0.15229398],\n",
       "       [0.15754312, 0.15754312, 0.15754312, 0.15754312, 0.15754312],\n",
       "       [0.1585716 , 0.1585716 , 0.1585716 , 0.1585716 , 0.1585716 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_copies_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84f2780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=scaler.inverse_transform(np.reshape(prediction_copies_array,(len(prediction),5)))[:,0]#预测的结果是缩小的，这里要逆变换回去，因为前面复制了5列，这里取第一列就可以了[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c86afce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([193.72238 , 194.32347 , 192.90332 , ..., 106.28031 , 108.153854,\n",
       "       108.52094 ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ec05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_copies_array = np.repeat(testY,5, axis=-1)#test的结果也是线复制5列，这样菜满足前面fit好的缩放函数，然后这里再和上面一样进行逆变换，取第一列\n",
    "\n",
    "original_copies_array.shape\n",
    "\n",
    "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),5)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "442e0222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([193.72238 , 194.32347 , 192.90332 , ..., 106.28031 , 108.153854,\n",
       "       108.52094 ], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cecfd7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Values--  [193.72238  194.32347  192.90332  ... 106.28031  108.153854 108.52094 ]\n",
      "\n",
      "Original Values--  [195.384613 194.461533 193.92308  ... 102.660004 104.550003 105.290001]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred Values-- \" ,pred)\n",
    "print(\"\\nOriginal Values-- \",original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1986d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07e37414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bfa9b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(original, color = 'red', label = 'Real  Stock Price')\n",
    "plt.plot(pred, color = 'blue', label = 'Predicted  Stock Price')\n",
    "plt.title(' Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(' Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ddb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a095e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_days_past=df.iloc[-1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "451dafea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>106.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>105.309998</td>\n",
       "      <td>106.279999</td>\n",
       "      <td>106.187027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High         Low       Close   Adj Close\n",
       "Date                                                        \n",
       "2021-09-29  106.0  107.0  105.309998  106.279999  106.187027"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_30_days_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92497be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_30_days_future=pd.read_csv(\"test.csv\",parse_dates=[\"Date\"],index_col=[0])\n",
    "df_30_days_future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7004371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>107.089996</td>\n",
       "      <td>102.949997</td>\n",
       "      <td>103.029999</td>\n",
       "      <td>102.939865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>106.389999</td>\n",
       "      <td>103.669998</td>\n",
       "      <td>105.820000</td>\n",
       "      <td>105.727425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04</th>\n",
       "      <td>107.080002</td>\n",
       "      <td>104.599998</td>\n",
       "      <td>104.900002</td>\n",
       "      <td>104.808235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>104.900002</td>\n",
       "      <td>104.808235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-06</th>\n",
       "      <td>104.419998</td>\n",
       "      <td>102.059998</td>\n",
       "      <td>104.330002</td>\n",
       "      <td>104.238731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-07</th>\n",
       "      <td>106.529999</td>\n",
       "      <td>104.330002</td>\n",
       "      <td>105.510002</td>\n",
       "      <td>105.417702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-08</th>\n",
       "      <td>106.220001</td>\n",
       "      <td>104.660004</td>\n",
       "      <td>104.720001</td>\n",
       "      <td>104.628387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11</th>\n",
       "      <td>105.760002</td>\n",
       "      <td>103.970001</td>\n",
       "      <td>104.080002</td>\n",
       "      <td>103.988953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-12</th>\n",
       "      <td>104.040001</td>\n",
       "      <td>101.559998</td>\n",
       "      <td>102.720001</td>\n",
       "      <td>102.630142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-13</th>\n",
       "      <td>103.199997</td>\n",
       "      <td>101.180000</td>\n",
       "      <td>102.360001</td>\n",
       "      <td>102.270454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14</th>\n",
       "      <td>103.650002</td>\n",
       "      <td>102.370003</td>\n",
       "      <td>102.739998</td>\n",
       "      <td>102.650116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-15</th>\n",
       "      <td>105.900002</td>\n",
       "      <td>103.190002</td>\n",
       "      <td>104.410004</td>\n",
       "      <td>104.318665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-18</th>\n",
       "      <td>104.570000</td>\n",
       "      <td>103.040001</td>\n",
       "      <td>104.120003</td>\n",
       "      <td>104.028915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-19</th>\n",
       "      <td>104.970001</td>\n",
       "      <td>103.580002</td>\n",
       "      <td>104.730003</td>\n",
       "      <td>104.638382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-20</th>\n",
       "      <td>106.019997</td>\n",
       "      <td>103.870003</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>105.907272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-21</th>\n",
       "      <td>106.389999</td>\n",
       "      <td>103.010002</td>\n",
       "      <td>103.150002</td>\n",
       "      <td>103.059761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>104.510002</td>\n",
       "      <td>102.550003</td>\n",
       "      <td>104.050003</td>\n",
       "      <td>103.958977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>105.989998</td>\n",
       "      <td>103.330002</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>105.207886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>110.970001</td>\n",
       "      <td>105.220001</td>\n",
       "      <td>107.440002</td>\n",
       "      <td>107.346008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>108.279999</td>\n",
       "      <td>103.690002</td>\n",
       "      <td>103.849998</td>\n",
       "      <td>103.759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>105.379997</td>\n",
       "      <td>103.099998</td>\n",
       "      <td>105.260002</td>\n",
       "      <td>105.167915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-29</th>\n",
       "      <td>105.239998</td>\n",
       "      <td>104.120003</td>\n",
       "      <td>104.870003</td>\n",
       "      <td>104.778259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>106.769997</td>\n",
       "      <td>105.279999</td>\n",
       "      <td>106.230003</td>\n",
       "      <td>106.137070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-02</th>\n",
       "      <td>107.139999</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>106.690002</td>\n",
       "      <td>106.596664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>106.339996</td>\n",
       "      <td>104.820000</td>\n",
       "      <td>105.970001</td>\n",
       "      <td>105.877296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-04</th>\n",
       "      <td>106.400002</td>\n",
       "      <td>104.290001</td>\n",
       "      <td>105.209999</td>\n",
       "      <td>105.117958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-05</th>\n",
       "      <td>109.650002</td>\n",
       "      <td>106.849998</td>\n",
       "      <td>108.739998</td>\n",
       "      <td>108.644867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>110.309998</td>\n",
       "      <td>108.320000</td>\n",
       "      <td>108.419998</td>\n",
       "      <td>108.325150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09</th>\n",
       "      <td>116.169998</td>\n",
       "      <td>110.480003</td>\n",
       "      <td>111.290001</td>\n",
       "      <td>111.192642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10</th>\n",
       "      <td>112.680000</td>\n",
       "      <td>108.110001</td>\n",
       "      <td>108.959999</td>\n",
       "      <td>108.864677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low       Close   Adj Close\n",
       "Date                                                      \n",
       "2021-09-30  107.089996  102.949997  103.029999  102.939865\n",
       "2021-10-01  106.389999  103.669998  105.820000  105.727425\n",
       "2021-10-04  107.080002  104.599998  104.900002  104.808235\n",
       "2021-10-05  106.000000  103.750000  104.900002  104.808235\n",
       "2021-10-06  104.419998  102.059998  104.330002  104.238731\n",
       "2021-10-07  106.529999  104.330002  105.510002  105.417702\n",
       "2021-10-08  106.220001  104.660004  104.720001  104.628387\n",
       "2021-10-11  105.760002  103.970001  104.080002  103.988953\n",
       "2021-10-12  104.040001  101.559998  102.720001  102.630142\n",
       "2021-10-13  103.199997  101.180000  102.360001  102.270454\n",
       "2021-10-14  103.650002  102.370003  102.739998  102.650116\n",
       "2021-10-15  105.900002  103.190002  104.410004  104.318665\n",
       "2021-10-18  104.570000  103.040001  104.120003  104.028915\n",
       "2021-10-19  104.970001  103.580002  104.730003  104.638382\n",
       "2021-10-20  106.019997  103.870003  106.000000  105.907272\n",
       "2021-10-21  106.389999  103.010002  103.150002  103.059761\n",
       "2021-10-22  104.510002  102.550003  104.050003  103.958977\n",
       "2021-10-25  105.989998  103.330002  105.300003  105.207886\n",
       "2021-10-26  110.970001  105.220001  107.440002  107.346008\n",
       "2021-10-27  108.279999  103.690002  103.849998  103.759148\n",
       "2021-10-28  105.379997  103.099998  105.260002  105.167915\n",
       "2021-10-29  105.239998  104.120003  104.870003  104.778259\n",
       "2021-11-01  106.769997  105.279999  106.230003  106.137070\n",
       "2021-11-02  107.139999  105.300003  106.690002  106.596664\n",
       "2021-11-03  106.339996  104.820000  105.970001  105.877296\n",
       "2021-11-04  106.400002  104.290001  105.209999  105.117958\n",
       "2021-11-05  109.650002  106.849998  108.739998  108.644867\n",
       "2021-11-08  110.309998  108.320000  108.419998  108.325150\n",
       "2021-11-09  116.169998  110.480003  111.290001  111.192642\n",
       "2021-11-10  112.680000  108.110001  108.959999  108.864677"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_30_days_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20277ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_days_future[\"Open\"]=0\n",
    "df_30_days_future=df_30_days_future[[\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\"]]\n",
    "old_scaled_array=scaler.transform(df_30_days_past)\n",
    "new_scaled_array=scaler.transform(df_30_days_future)\n",
    "new_scaled_df=pd.DataFrame(new_scaled_array)\n",
    "new_scaled_df.iloc[:,0]=np.nan\n",
    "full_df=pd.concat([pd.DataFrame(old_scaled_array),new_scaled_df]).reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0dcb1ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88cfa224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.150135</td>\n",
       "      <td>0.349458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152749</td>\n",
       "      <td>0.171268</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>0.367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>0.175349</td>\n",
       "      <td>0.159063</td>\n",
       "      <td>0.365924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171024</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.380645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161242</td>\n",
       "      <td>0.174766</td>\n",
       "      <td>0.160565</td>\n",
       "      <td>0.368694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4\n",
       "26 NaN  0.143640  0.164162  0.150135  0.349458\n",
       "27 NaN  0.152749  0.171268  0.159953  0.367565\n",
       "28 NaN  0.154599  0.175349  0.159063  0.365924\n",
       "29 NaN  0.171024  0.181345  0.167045  0.380645\n",
       "30 NaN  0.161242  0.174766  0.160565  0.368694"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2f66518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.151509</td>\n",
       "      <td>0.145321</td>\n",
       "      <td>0.166993</td>\n",
       "      <td>0.153111</td>\n",
       "      <td>0.354947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145574</td>\n",
       "      <td>0.160442</td>\n",
       "      <td>0.144071</td>\n",
       "      <td>0.338276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143611</td>\n",
       "      <td>0.162441</td>\n",
       "      <td>0.151831</td>\n",
       "      <td>0.352587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.165022</td>\n",
       "      <td>0.149273</td>\n",
       "      <td>0.347868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142518</td>\n",
       "      <td>0.162663</td>\n",
       "      <td>0.149273</td>\n",
       "      <td>0.347868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138090</td>\n",
       "      <td>0.157971</td>\n",
       "      <td>0.147687</td>\n",
       "      <td>0.344944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144004</td>\n",
       "      <td>0.164273</td>\n",
       "      <td>0.150969</td>\n",
       "      <td>0.350997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>0.165189</td>\n",
       "      <td>0.148772</td>\n",
       "      <td>0.346944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141846</td>\n",
       "      <td>0.163274</td>\n",
       "      <td>0.146992</td>\n",
       "      <td>0.343662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137025</td>\n",
       "      <td>0.156583</td>\n",
       "      <td>0.143209</td>\n",
       "      <td>0.336685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.134670</td>\n",
       "      <td>0.155529</td>\n",
       "      <td>0.142208</td>\n",
       "      <td>0.334839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135931</td>\n",
       "      <td>0.158832</td>\n",
       "      <td>0.143265</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142238</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.345354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138510</td>\n",
       "      <td>0.160692</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>0.343867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139631</td>\n",
       "      <td>0.162191</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.346996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142574</td>\n",
       "      <td>0.162996</td>\n",
       "      <td>0.152332</td>\n",
       "      <td>0.353510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143611</td>\n",
       "      <td>0.160609</td>\n",
       "      <td>0.144405</td>\n",
       "      <td>0.338891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138342</td>\n",
       "      <td>0.159332</td>\n",
       "      <td>0.146908</td>\n",
       "      <td>0.343508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142490</td>\n",
       "      <td>0.161497</td>\n",
       "      <td>0.150385</td>\n",
       "      <td>0.349920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156449</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>0.156337</td>\n",
       "      <td>0.360897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148909</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.146352</td>\n",
       "      <td>0.342482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.150274</td>\n",
       "      <td>0.349714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140388</td>\n",
       "      <td>0.163690</td>\n",
       "      <td>0.149189</td>\n",
       "      <td>0.347714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144677</td>\n",
       "      <td>0.166910</td>\n",
       "      <td>0.152972</td>\n",
       "      <td>0.354690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145714</td>\n",
       "      <td>0.166966</td>\n",
       "      <td>0.154251</td>\n",
       "      <td>0.357050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143471</td>\n",
       "      <td>0.165633</td>\n",
       "      <td>0.152249</td>\n",
       "      <td>0.353356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.150135</td>\n",
       "      <td>0.349458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152749</td>\n",
       "      <td>0.171268</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>0.367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>0.175349</td>\n",
       "      <td>0.159063</td>\n",
       "      <td>0.365924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171024</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.380645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161242</td>\n",
       "      <td>0.174766</td>\n",
       "      <td>0.160565</td>\n",
       "      <td>0.368694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0   0.151509  0.145321  0.166993  0.153111  0.354947\n",
       "1        NaN  0.145574  0.160442  0.144071  0.338276\n",
       "2        NaN  0.143611  0.162441  0.151831  0.352587\n",
       "3        NaN  0.145546  0.165022  0.149273  0.347868\n",
       "4        NaN  0.142518  0.162663  0.149273  0.347868\n",
       "5        NaN  0.138090  0.157971  0.147687  0.344944\n",
       "6        NaN  0.144004  0.164273  0.150969  0.350997\n",
       "7        NaN  0.143135  0.165189  0.148772  0.346944\n",
       "8        NaN  0.141846  0.163274  0.146992  0.343662\n",
       "9        NaN  0.137025  0.156583  0.143209  0.336685\n",
       "10       NaN  0.134670  0.155529  0.142208  0.334839\n",
       "11       NaN  0.135931  0.158832  0.143265  0.336788\n",
       "12       NaN  0.142238  0.161108  0.147910  0.345354\n",
       "13       NaN  0.138510  0.160692  0.147103  0.343867\n",
       "14       NaN  0.139631  0.162191  0.148800  0.346996\n",
       "15       NaN  0.142574  0.162996  0.152332  0.353510\n",
       "16       NaN  0.143611  0.160609  0.144405  0.338891\n",
       "17       NaN  0.138342  0.159332  0.146908  0.343508\n",
       "18       NaN  0.142490  0.161497  0.150385  0.349920\n",
       "19       NaN  0.156449  0.166744  0.156337  0.360897\n",
       "20       NaN  0.148909  0.162496  0.146352  0.342482\n",
       "21       NaN  0.140781  0.160858  0.150274  0.349714\n",
       "22       NaN  0.140388  0.163690  0.149189  0.347714\n",
       "23       NaN  0.144677  0.166910  0.152972  0.354690\n",
       "24       NaN  0.145714  0.166966  0.154251  0.357050\n",
       "25       NaN  0.143471  0.165633  0.152249  0.353356\n",
       "26       NaN  0.143640  0.164162  0.150135  0.349458\n",
       "27       NaN  0.152749  0.171268  0.159953  0.367565\n",
       "28       NaN  0.154599  0.175349  0.159063  0.365924\n",
       "29       NaN  0.171024  0.181345  0.167045  0.380645\n",
       "30       NaN  0.161242  0.174766  0.160565  0.368694"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8cc462a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48bf070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_scaled_array=full_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91fdcf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_scaled_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "252d2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_df_scaled_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "547622aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "all_data=[]\n",
    "time_step=1\n",
    "for i in range(1,len(full_df_scaled_array)):\n",
    "    data_x=[]\n",
    "    data_x.append(full_df_scaled_array[i-time_step:i,1:full_df_scaled_array.shape[1]])\n",
    "    data_x=np.array(data_x)\n",
    "    #print(data_x)\n",
    "    prediction=my_model.predict(data_x)\n",
    "    all_data.append(prediction)\n",
    "    full_df.iloc[i,0]=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05929d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.15966299]], dtype=float32),\n",
       " array([[0.15665498]], dtype=float32),\n",
       " array([[0.15683585]], dtype=float32),\n",
       " array([[0.15878749]], dtype=float32),\n",
       " array([[0.15628088]], dtype=float32),\n",
       " array([[0.15202975]], dtype=float32),\n",
       " array([[0.15777028]], dtype=float32),\n",
       " array([[0.15763512]], dtype=float32),\n",
       " array([[0.15611053]], dtype=float32),\n",
       " array([[0.15072879]], dtype=float32),\n",
       " array([[0.14906973]], dtype=float32),\n",
       " array([[0.1511347]], dtype=float32),\n",
       " array([[0.15542936]], dtype=float32),\n",
       " array([[0.15336251]], dtype=float32),\n",
       " array([[0.15462333]], dtype=float32),\n",
       " array([[0.15657356]], dtype=float32),\n",
       " array([[0.15576014]], dtype=float32),\n",
       " array([[0.15269697]], dtype=float32),\n",
       " array([[0.1558199]], dtype=float32),\n",
       " array([[0.16523924]], dtype=float32),\n",
       " array([[0.15928054]], dtype=float32),\n",
       " array([[0.15469396]], dtype=float32),\n",
       " array([[0.15564919]], dtype=float32),\n",
       " array([[0.15930057]], dtype=float32),\n",
       " array([[0.15989268]], dtype=float32),\n",
       " array([[0.15813091]], dtype=float32),\n",
       " array([[0.15750799]], dtype=float32),\n",
       " array([[0.16544828]], dtype=float32),\n",
       " array([[0.16806537]], dtype=float32),\n",
       " array([[0.17912894]], dtype=float32)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "379cf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array=np.array(all_data)\n",
    "new_array=new_array.reshape(-1,1)\n",
    "prediction_copies_array = np.repeat(new_array,5, axis=-1)\n",
    "y_pred_future_30_days = scaler.inverse_transform(np.reshape(prediction_copies_array,(len(new_array),5)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ab9307c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108.910484, 107.83686 , 107.90141 , 108.598   , 107.70333 ,\n",
       "       106.186005, 108.23493 , 108.18669 , 107.642525, 105.721664,\n",
       "       105.1295  , 105.86654 , 107.39941 , 106.6617  , 107.11171 ,\n",
       "       107.8078  , 107.51746 , 106.42415 , 107.538795, 110.90078 ,\n",
       "       108.77398 , 107.136925, 107.47787 , 108.78113 , 108.99246 ,\n",
       "       108.36365 , 108.14131 , 110.97539 , 111.909485, 115.85833 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_future_30_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "265bfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eed9c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_pred_future_30_days, color = 'blue', label = 'Predicted  Stock Price')\n",
    "plt.title(' Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(' Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f766d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcbe5698",
   "metadata": {},
   "source": [
    "# END!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
